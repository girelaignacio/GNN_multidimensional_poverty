{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3QBFCJifrdZ0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.data\n",
    "import torch_geometric.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read spatial data: Nigeria DHS 20-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uR4QbIm94HSw"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "df = gpd.read_file(\"../data/nga_dhs20-21.shp\")\n",
    "gdf = gpd.GeoDataFrame(df, crs=\"EPSG:4326\")\n",
    "#gdf = gdf.to_crs(\"EPSG:32617\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "BRVzB0Jp65lW",
    "outputId": "f473b51e-a908-4bed-ceb4-c146d6d85c82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\girel\\AppData\\Local\\Temp\\ipykernel_14700\\3951700624.py:1: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf.geometry.centroid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       POINT (8.50694 7.72005)\n",
       "1       POINT (8.55214 7.71792)\n",
       "2       POINT (8.99118 7.34660)\n",
       "3       POINT (8.14976 7.21013)\n",
       "4       POINT (8.40813 6.88090)\n",
       "                 ...           \n",
       "1384    POINT (3.58764 7.82843)\n",
       "1385    POINT (3.34299 8.05012)\n",
       "1386    POINT (3.01766 7.94763)\n",
       "1387    POINT (3.29102 7.34129)\n",
       "1388    POINT (3.94804 7.78566)\n",
       "Length: 1389, dtype: geometry"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTvhxUcW5qgp",
    "outputId": "990f876c-968f-4d49-9725-a3b13fd93b64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\girel\\AppData\\Local\\Temp\\ipykernel_14700\\1084201971.py:1: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroids = np.array([(point.x, point.y) for point in df.geometry.centroid])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1389, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = np.array([(point.x, point.y) for point in df.geometry.centroid])\n",
    "centroids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build distance matrix\n",
    "\n",
    "We build a proximity matrix between the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "lx3-Bvbl5qsk",
    "outputId": "534c288e-adc0-4b3d-8eba-a18a3bba16e2"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "distance_matrix = cdist(centroids, centroids, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Rs-v7sM5q5T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.04525601, 0.61152249, ..., 5.49399072, 5.22965119,\n",
       "        4.55936917],\n",
       "       [0.04525601, 0.        , 0.57501069, ..., 5.53924603, 5.27458718,\n",
       "        4.60460133],\n",
       "       [0.61152249, 0.57501069, 0.        , ..., 6.00368437, 5.70016848,\n",
       "        5.06222254],\n",
       "       ...,\n",
       "       [5.49399072, 5.53924603, 6.00368437, ..., 0.        , 0.66511658,\n",
       "        0.94437114],\n",
       "       [5.22965119, 5.27458718, 5.70016848, ..., 0.66511658, 0.        ,\n",
       "        0.79318793],\n",
       "       [4.55936917, 4.60460133, 5.06222254, ..., 0.94437114, 0.79318793,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1389, 1389)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.817615452436154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance = np.max(distance_matrix)\n",
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_proximity_matrix = np.zeros_like(distance_matrix)\n",
    "for i in range(len(distance_matrix)):\n",
    "    for j in range(len(distance_matrix)):\n",
    "        proximity = (max_distance - distance_matrix[i, j]) / max_distance\n",
    "        proximity = max(0, proximity)\n",
    "        weighted_proximity_matrix[i, j] = proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(weighted_proximity_matrix.min(),weighted_proximity_matrix.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "weighted_proximity_matrix[weighted_proximity_matrix < threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99759502, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.99759502, 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_proximity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_proximity_matrix[np.diag_indices_from(weighted_proximity_matrix)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transform data to tensor\n",
    "\n",
    "Create torch_geometric.data.Data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform proximity matrix to tensor and create edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = torch.tensor(weighted_proximity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = adj_matrix.nonzero().t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 1388, 1388, 1388],\n",
       "        [   1,    8,    9,  ..., 1358, 1380, 1383]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get edge attributes (given by proximity of clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WIBVjlFAI4Vt"
   },
   "outputs": [],
   "source": [
    "edge_attr = []\n",
    "for i in range(edges.size(1)):\n",
    "    edge_attr.append([adj_matrix[edges[0][i], edges[1][0]]])\n",
    "\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dhsclst', 'd_cm', 'd_nutr', 'd_satt', 'd_educ', 'd_elct', 'd_wtr',\n",
       "       'd_sani', 'd_hsg', 'd_ckfl', 'd_asst', 'score', 'sexfeml', 'sexmale',\n",
       "       'agc70_4', 'a710_14', 'a715_17', 'a718_59', 'agc75_9', 'agc760_',\n",
       "       'arearrl', 'arearbn', 'reginAb', 'rgnAdmw', 'rgnAk_I', 'rgnAnmb',\n",
       "       'regnBch', 'rgnByls', 'reginBn', 'regnBrn', 'rgnCr_R', 'regnDlt',\n",
       "       'rgnEbny', 'reginEd', 'regnEkt', 'regnEng', 'regnFCT', 'regnGmb',\n",
       "       'reginIm', 'regnJgw', 'regnKdn', 'reginKn', 'rgnKtsn', 'regnKbb',\n",
       "       'reginKg', 'regnKwr', 'regnLgs', 'rgnNsrw', 'regnNgr', 'regnOgn',\n",
       "       'regnOnd', 'regnOsn', 'reginOy', 'regnPlt', 'rgnRvrs', 'regnSkt',\n",
       "       'regnTrb', 'reginYb', 'rgnZmfr', 'hdshpf_', 'hdshpm_', 'categry',\n",
       "       'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(gdf.columns[list(range(11, gdf.shape[1]-4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid multicollineality\n",
    "for i in ['sexmale','agc760_','arearrl','reginAb','score']:#,'hdshpm_']:#,\n",
    "         #'d_cm', 'd_nutr', 'd_satt', 'd_educ']:\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sexfeml', 'agc70_4', 'a710_14', 'a715_17', 'a718_59', 'agc75_9', 'arearbn', 'rgnAdmw', 'rgnAk_I', 'rgnAnmb', 'regnBch', 'rgnByls', 'reginBn', 'regnBrn', 'rgnCr_R', 'regnDlt', 'rgnEbny', 'reginEd', 'regnEkt', 'regnEng', 'regnFCT', 'regnGmb', 'reginIm', 'regnJgw', 'regnKdn', 'reginKn', 'rgnKtsn', 'regnKbb', 'reginKg', 'regnKwr', 'regnLgs', 'rgnNsrw', 'regnNgr', 'regnOgn', 'regnOnd', 'regnOsn', 'reginOy', 'regnPlt', 'rgnRvrs', 'regnSkt', 'regnTrb', 'reginYb', 'rgnZmfr']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wTOdbO8IQI4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1389, 43])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(np.array(gdf[features]))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0804, 0.0678, 0.0451,  ..., 0.1570, 0.5354, 0.1026])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if task == \"reg\":\n",
    "    target_tensor = torch.tensor(gdf['score'], dtype=torch.float)\n",
    "else: \n",
    "    target = pd.Categorical(gdf['categry'])\n",
    "    numerical_categories = target.codes\n",
    "    print(np.unique(numerical_categories))\n",
    "    target_tensor = torch.tensor(numerical_categories, dtype=torch.long) \n",
    "target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYrOagwsPxlj",
    "outputId": "703aa669-2e31-4795-c53f-fe6d45373a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1389, 43], edge_index=[2, 8956], edge_attr=[8956, 1], y=[1389])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = torch_geometric.data.Data(x=x, edge_index=edges, edge_attr = edge_attr,y=target_tensor)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "c1BM5KgFQyxZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 46 artists>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "\n",
    "# Get list of degrees for each node\n",
    "degrees = degree(graph.edge_index[0]).numpy()\n",
    "\n",
    "# Count the number of nodes for each degree\n",
    "numbers = Counter(degrees)\n",
    "\n",
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(18, 7))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "plt.bar(numbers.keys(),\n",
    "        numbers.values(),\n",
    "        color='#0A047A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1389"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of nodes\n",
    "num_nodes = graph.num_nodes\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111 138 140\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sizes of the train, validation, and test sets\n",
    "train_size = int(0.8 * num_nodes)\n",
    "val_size = int(0.1 * num_nodes)\n",
    "test_size = num_nodes - train_size - val_size\n",
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1389, 43], edge_index=[2, 8956], edge_attr=[8956, 1], y=[1389], train_mask=[1389], val_mask=[1389], test_mask=[1389])\n"
     ]
    }
   ],
   "source": [
    "# Create random permutations of node indices\n",
    "# Set the random seed\n",
    "seed = 91218\n",
    "torch.manual_seed(seed)\n",
    "perm = torch.randperm(num_nodes)\n",
    "\n",
    "# Create boolean masks\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[perm[:train_size]] = True\n",
    "val_mask[perm[train_size:train_size + val_size]] = True\n",
    "test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "# Add the masks to the graph object\n",
    "graph.train_mask = train_mask\n",
    "graph.val_mask = val_mask\n",
    "graph.test_mask = test_mask\n",
    "\n",
    "print(graph) #now the graph contains the masks."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes = graph.train_mask,\n",
    "    batch_size = int(train_size//8),\n",
    "    num_neighbors = [1,10],\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes = graph.val_mask,\n",
    "    batch_size = int(val_size//3),\n",
    "    num_neighbors = [1,10]\n",
    ")\n",
    "\n",
    "test_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes = graph.test_mask,\n",
    "    batch_size = int(test_size//3),\n",
    "    num_neighbors = [1,10]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #check if cuda is available\n",
    "graph = graph.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "train_nodes = torch.where(train_mask)[0]\n",
    "sub_edge_index, _ = subgraph(train_mask, graph.edge_index, relabel_nodes=True)\n",
    "train_x = graph.x[train_nodes]\n",
    "train_y = graph.y[train_nodes]\n",
    "train_data = torch_geometric.data.Data(x=train_x, y=train_y, edge_index=sub_edge_index)\n",
    "train_loader = torch_geometric.loader.DataLoader([train_data], batch_size=int(train_size//20), shuffle=True)\n",
    "\n",
    "val_nodes = torch.where(val_mask)[0]\n",
    "sub_edge_index, _ = subgraph(val_mask, graph.edge_index, relabel_nodes=True)\n",
    "val_x = graph.x[val_nodes]\n",
    "val_y = graph.y[val_nodes]\n",
    "val_data = torch_geometric.data.Data(x=val_x, y=val_y, edge_index=sub_edge_index)\n",
    "val_loader = torch_geometric.loader.DataLoader([val_data], batch_size=val_size)\n",
    "\n",
    "test_nodes = torch.where(test_mask)[0]\n",
    "sub_edge_index, _ = subgraph(test_mask, graph.edge_index, relabel_nodes=True)\n",
    "test_x = graph.x[test_nodes]\n",
    "test_y = graph.y[test_nodes]\n",
    "test_data = torch_geometric.data.Data(x=test_x, y=test_y, edge_index=sub_edge_index)\n",
    "test_loader = torch_geometric.loader.DataLoader([test_data], batch_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention network\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out, n_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads = n_heads)\n",
    "        self.norm1 = torch.nn.LayerNorm(dim_h * n_heads)\n",
    "        self.gat2 = GATv2Conv(dim_h*n_heads, dim_out, heads = 1)\n",
    "        self.norm2 = torch.nn.LayerNorm(16*n_heads)\n",
    "        self.gat3 = GATv2Conv(n_heads*n_heads, 16, heads = 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x1 = F.dropout(x, p = 0.7, training = self.training)\n",
    "        x = self.gat1(x1, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x, F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = graph.x.size(1)  \n",
    "dim_h = 32\n",
    "if task == \"reg\":\n",
    "    dim_out = 1\n",
    "else:\n",
    "    dim_out = len(graph.y.unique()) # Number of classes \n",
    "n_heads = 16\n",
    "\n",
    "# Create an instance of your GAT model\n",
    "model = GAT(dim_in, dim_h, dim_out, n_heads)\n",
    "untrained = GAT(dim_in, dim_h, dim_out, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),weight_decay=5e-4)\n",
    "if task == \"reg\":\n",
    "    criterion = torch.nn.MSELoss()\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (gat1): GATv2Conv(43, 32, heads=16)\n",
      "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (gat2): GATv2Conv(512, 1, heads=1)\n",
      "  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (gat3): GATv2Conv(256, 16, heads=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Loss: 3.1611, Val Loss: 0.5485, Test Loss: 0.5142\n",
      "Epoch 2/500, Train Loss: 1.0613, Val Loss: 1.0655, Test Loss: 0.7528\n",
      "Epoch 3/500, Train Loss: 0.9114, Val Loss: 2.2703, Test Loss: 1.8749\n",
      "Epoch 4/500, Train Loss: 1.7039, Val Loss: 2.4458, Test Loss: 2.1222\n",
      "Epoch 5/500, Train Loss: 1.6618, Val Loss: 1.8182, Test Loss: 1.6000\n",
      "Epoch 6/500, Train Loss: 1.2538, Val Loss: 0.9754, Test Loss: 0.8505\n",
      "Epoch 7/500, Train Loss: 0.8907, Val Loss: 0.3422, Test Loss: 0.2864\n",
      "Epoch 8/500, Train Loss: 0.5680, Val Loss: 0.0800, Test Loss: 0.0642\n",
      "Epoch 9/500, Train Loss: 0.5996, Val Loss: 0.0937, Test Loss: 0.0948\n",
      "Epoch 10/500, Train Loss: 0.8361, Val Loss: 0.1689, Test Loss: 0.1700\n",
      "Epoch 11/500, Train Loss: 0.9210, Val Loss: 0.1594, Test Loss: 0.1578\n",
      "Epoch 12/500, Train Loss: 1.0134, Val Loss: 0.0834, Test Loss: 0.0852\n",
      "Epoch 13/500, Train Loss: 0.7877, Val Loss: 0.0474, Test Loss: 0.0622\n",
      "Epoch 14/500, Train Loss: 0.5946, Val Loss: 0.1258, Test Loss: 0.1600\n",
      "Epoch 15/500, Train Loss: 0.5009, Val Loss: 0.3107, Test Loss: 0.3647\n",
      "Epoch 16/500, Train Loss: 0.5230, Val Loss: 0.5387, Test Loss: 0.6076\n",
      "Epoch 17/500, Train Loss: 0.5574, Val Loss: 0.7029, Test Loss: 0.7794\n",
      "Epoch 18/500, Train Loss: 0.7029, Val Loss: 0.7338, Test Loss: 0.8075\n",
      "Epoch 19/500, Train Loss: 0.6739, Val Loss: 0.6403, Test Loss: 0.7036\n",
      "Epoch 20/500, Train Loss: 0.6630, Val Loss: 0.4697, Test Loss: 0.5177\n",
      "Epoch 21/500, Train Loss: 0.5636, Val Loss: 0.2797, Test Loss: 0.3116\n",
      "Epoch 22/500, Train Loss: 0.5419, Val Loss: 0.1252, Test Loss: 0.1413\n",
      "Epoch 23/500, Train Loss: 0.4644, Val Loss: 0.0521, Test Loss: 0.0569\n",
      "Epoch 24/500, Train Loss: 0.4206, Val Loss: 0.0414, Test Loss: 0.0404\n",
      "Epoch 25/500, Train Loss: 0.5853, Val Loss: 0.0497, Test Loss: 0.0471\n",
      "Epoch 26/500, Train Loss: 0.5941, Val Loss: 0.0458, Test Loss: 0.0435\n",
      "Epoch 27/500, Train Loss: 0.5395, Val Loss: 0.0357, Test Loss: 0.0341\n",
      "Epoch 28/500, Train Loss: 0.5320, Val Loss: 0.0397, Test Loss: 0.0388\n",
      "Epoch 29/500, Train Loss: 0.5175, Val Loss: 0.0793, Test Loss: 0.0796\n",
      "Epoch 30/500, Train Loss: 0.4690, Val Loss: 0.1467, Test Loss: 0.1491\n",
      "Epoch 31/500, Train Loss: 0.4428, Val Loss: 0.2361, Test Loss: 0.2411\n",
      "Epoch 32/500, Train Loss: 0.4624, Val Loss: 0.3011, Test Loss: 0.3076\n",
      "Epoch 33/500, Train Loss: 0.4840, Val Loss: 0.3137, Test Loss: 0.3213\n",
      "Epoch 34/500, Train Loss: 0.5364, Val Loss: 0.2688, Test Loss: 0.2763\n",
      "Epoch 35/500, Train Loss: 0.4369, Val Loss: 0.2011, Test Loss: 0.2080\n",
      "Epoch 36/500, Train Loss: 0.3986, Val Loss: 0.1314, Test Loss: 0.1377\n",
      "Epoch 37/500, Train Loss: 0.4517, Val Loss: 0.0722, Test Loss: 0.0786\n",
      "Epoch 38/500, Train Loss: 0.4166, Val Loss: 0.0389, Test Loss: 0.0453\n",
      "Epoch 39/500, Train Loss: 0.4124, Val Loss: 0.0286, Test Loss: 0.0349\n",
      "Epoch 40/500, Train Loss: 0.4053, Val Loss: 0.0272, Test Loss: 0.0336\n",
      "Epoch 41/500, Train Loss: 0.4021, Val Loss: 0.0268, Test Loss: 0.0327\n",
      "Epoch 42/500, Train Loss: 0.4324, Val Loss: 0.0306, Test Loss: 0.0361\n",
      "Epoch 43/500, Train Loss: 0.3880, Val Loss: 0.0471, Test Loss: 0.0521\n",
      "Epoch 44/500, Train Loss: 0.3696, Val Loss: 0.0748, Test Loss: 0.0789\n",
      "Epoch 45/500, Train Loss: 0.3899, Val Loss: 0.1151, Test Loss: 0.1175\n",
      "Epoch 46/500, Train Loss: 0.3764, Val Loss: 0.1492, Test Loss: 0.1487\n",
      "Epoch 47/500, Train Loss: 0.3868, Val Loss: 0.1539, Test Loss: 0.1512\n",
      "Epoch 48/500, Train Loss: 0.4030, Val Loss: 0.1316, Test Loss: 0.1274\n",
      "Epoch 49/500, Train Loss: 0.4524, Val Loss: 0.1011, Test Loss: 0.0960\n",
      "Epoch 50/500, Train Loss: 0.3738, Val Loss: 0.0689, Test Loss: 0.0648\n",
      "Epoch 51/500, Train Loss: 0.3802, Val Loss: 0.0436, Test Loss: 0.0417\n",
      "Epoch 52/500, Train Loss: 0.3779, Val Loss: 0.0286, Test Loss: 0.0290\n",
      "Epoch 53/500, Train Loss: 0.3673, Val Loss: 0.0239, Test Loss: 0.0259\n",
      "Epoch 54/500, Train Loss: 0.3689, Val Loss: 0.0233, Test Loss: 0.0253\n",
      "Epoch 55/500, Train Loss: 0.3678, Val Loss: 0.0250, Test Loss: 0.0256\n",
      "Epoch 56/500, Train Loss: 0.3785, Val Loss: 0.0301, Test Loss: 0.0293\n",
      "Epoch 57/500, Train Loss: 0.3766, Val Loss: 0.0448, Test Loss: 0.0425\n",
      "Epoch 58/500, Train Loss: 0.3702, Val Loss: 0.0718, Test Loss: 0.0687\n",
      "Epoch 59/500, Train Loss: 0.3755, Val Loss: 0.0959, Test Loss: 0.0935\n",
      "Epoch 60/500, Train Loss: 0.3658, Val Loss: 0.1162, Test Loss: 0.1152\n",
      "Epoch 61/500, Train Loss: 0.3290, Val Loss: 0.1195, Test Loss: 0.1208\n",
      "Epoch 62/500, Train Loss: 0.3919, Val Loss: 0.1086, Test Loss: 0.1117\n",
      "Epoch 63/500, Train Loss: 0.3474, Val Loss: 0.0892, Test Loss: 0.0936\n",
      "Epoch 64/500, Train Loss: 0.3454, Val Loss: 0.0719, Test Loss: 0.0772\n",
      "Epoch 65/500, Train Loss: 0.3763, Val Loss: 0.0512, Test Loss: 0.0567\n",
      "Epoch 66/500, Train Loss: 0.3021, Val Loss: 0.0364, Test Loss: 0.0419\n",
      "Epoch 67/500, Train Loss: 0.3221, Val Loss: 0.0298, Test Loss: 0.0354\n",
      "Epoch 68/500, Train Loss: 0.3239, Val Loss: 0.0267, Test Loss: 0.0326\n",
      "Epoch 69/500, Train Loss: 0.3371, Val Loss: 0.0279, Test Loss: 0.0339\n",
      "Epoch 70/500, Train Loss: 0.3406, Val Loss: 0.0349, Test Loss: 0.0408\n",
      "Epoch 71/500, Train Loss: 0.3155, Val Loss: 0.0433, Test Loss: 0.0486\n",
      "Epoch 72/500, Train Loss: 0.3115, Val Loss: 0.0525, Test Loss: 0.0570\n",
      "Epoch 73/500, Train Loss: 0.3169, Val Loss: 0.0571, Test Loss: 0.0611\n",
      "Epoch 74/500, Train Loss: 0.3442, Val Loss: 0.0556, Test Loss: 0.0590\n",
      "Epoch 75/500, Train Loss: 0.3063, Val Loss: 0.0507, Test Loss: 0.0539\n",
      "Epoch 76/500, Train Loss: 0.3221, Val Loss: 0.0453, Test Loss: 0.0484\n",
      "Epoch 77/500, Train Loss: 0.2887, Val Loss: 0.0423, Test Loss: 0.0454\n",
      "Epoch 78/500, Train Loss: 0.2697, Val Loss: 0.0414, Test Loss: 0.0441\n",
      "Epoch 79/500, Train Loss: 0.3073, Val Loss: 0.0369, Test Loss: 0.0397\n",
      "Epoch 80/500, Train Loss: 0.2819, Val Loss: 0.0349, Test Loss: 0.0374\n",
      "Epoch 81/500, Train Loss: 0.2701, Val Loss: 0.0340, Test Loss: 0.0361\n",
      "Epoch 82/500, Train Loss: 0.3138, Val Loss: 0.0331, Test Loss: 0.0349\n",
      "Epoch 83/500, Train Loss: 0.2995, Val Loss: 0.0375, Test Loss: 0.0385\n",
      "Epoch 84/500, Train Loss: 0.2966, Val Loss: 0.0398, Test Loss: 0.0404\n",
      "Epoch 85/500, Train Loss: 0.3163, Val Loss: 0.0421, Test Loss: 0.0426\n",
      "Epoch 86/500, Train Loss: 0.2788, Val Loss: 0.0466, Test Loss: 0.0467\n",
      "Epoch 87/500, Train Loss: 0.2998, Val Loss: 0.0474, Test Loss: 0.0474\n",
      "Epoch 88/500, Train Loss: 0.2655, Val Loss: 0.0476, Test Loss: 0.0477\n",
      "Epoch 89/500, Train Loss: 0.3266, Val Loss: 0.0442, Test Loss: 0.0444\n",
      "Epoch 90/500, Train Loss: 0.2703, Val Loss: 0.0410, Test Loss: 0.0410\n",
      "Epoch 91/500, Train Loss: 0.2821, Val Loss: 0.0361, Test Loss: 0.0364\n",
      "Epoch 92/500, Train Loss: 0.2684, Val Loss: 0.0339, Test Loss: 0.0345\n",
      "Epoch 93/500, Train Loss: 0.2616, Val Loss: 0.0287, Test Loss: 0.0297\n",
      "Epoch 94/500, Train Loss: 0.2887, Val Loss: 0.0287, Test Loss: 0.0300\n",
      "Epoch 95/500, Train Loss: 0.3064, Val Loss: 0.0327, Test Loss: 0.0338\n",
      "Epoch 96/500, Train Loss: 0.3163, Val Loss: 0.0377, Test Loss: 0.0388\n",
      "Epoch 97/500, Train Loss: 0.2583, Val Loss: 0.0418, Test Loss: 0.0429\n",
      "Epoch 98/500, Train Loss: 0.2935, Val Loss: 0.0414, Test Loss: 0.0425\n",
      "Epoch 99/500, Train Loss: 0.2706, Val Loss: 0.0384, Test Loss: 0.0400\n",
      "Epoch 100/500, Train Loss: 0.2253, Val Loss: 0.0336, Test Loss: 0.0363\n",
      "Epoch 101/500, Train Loss: 0.2571, Val Loss: 0.0285, Test Loss: 0.0323\n",
      "Epoch 102/500, Train Loss: 0.2778, Val Loss: 0.0229, Test Loss: 0.0276\n",
      "Epoch 103/500, Train Loss: 0.2574, Val Loss: 0.0217, Test Loss: 0.0266\n",
      "Epoch 104/500, Train Loss: 0.2667, Val Loss: 0.0242, Test Loss: 0.0288\n",
      "Epoch 105/500, Train Loss: 0.2337, Val Loss: 0.0300, Test Loss: 0.0338\n",
      "Epoch 106/500, Train Loss: 0.2729, Val Loss: 0.0341, Test Loss: 0.0372\n",
      "Epoch 107/500, Train Loss: 0.2771, Val Loss: 0.0374, Test Loss: 0.0397\n",
      "Epoch 108/500, Train Loss: 0.2394, Val Loss: 0.0396, Test Loss: 0.0414\n",
      "Epoch 109/500, Train Loss: 0.2529, Val Loss: 0.0408, Test Loss: 0.0421\n",
      "Epoch 110/500, Train Loss: 0.2269, Val Loss: 0.0442, Test Loss: 0.0448\n",
      "Epoch 111/500, Train Loss: 0.2375, Val Loss: 0.0406, Test Loss: 0.0413\n",
      "Epoch 112/500, Train Loss: 0.2417, Val Loss: 0.0363, Test Loss: 0.0374\n",
      "Epoch 113/500, Train Loss: 0.2306, Val Loss: 0.0338, Test Loss: 0.0351\n",
      "Epoch 114/500, Train Loss: 0.2475, Val Loss: 0.0291, Test Loss: 0.0310\n",
      "Epoch 115/500, Train Loss: 0.2273, Val Loss: 0.0252, Test Loss: 0.0279\n",
      "Epoch 116/500, Train Loss: 0.2261, Val Loss: 0.0224, Test Loss: 0.0258\n",
      "Epoch 117/500, Train Loss: 0.2377, Val Loss: 0.0236, Test Loss: 0.0267\n",
      "Epoch 118/500, Train Loss: 0.2298, Val Loss: 0.0268, Test Loss: 0.0290\n",
      "Epoch 119/500, Train Loss: 0.2492, Val Loss: 0.0311, Test Loss: 0.0326\n",
      "Epoch 120/500, Train Loss: 0.2142, Val Loss: 0.0379, Test Loss: 0.0385\n",
      "Epoch 121/500, Train Loss: 0.2166, Val Loss: 0.0452, Test Loss: 0.0451\n",
      "Epoch 122/500, Train Loss: 0.2301, Val Loss: 0.0444, Test Loss: 0.0448\n",
      "Epoch 123/500, Train Loss: 0.2073, Val Loss: 0.0398, Test Loss: 0.0410\n",
      "Epoch 124/500, Train Loss: 0.2309, Val Loss: 0.0354, Test Loss: 0.0375\n",
      "Epoch 125/500, Train Loss: 0.2072, Val Loss: 0.0315, Test Loss: 0.0344\n",
      "Epoch 126/500, Train Loss: 0.2090, Val Loss: 0.0276, Test Loss: 0.0314\n",
      "Epoch 127/500, Train Loss: 0.1911, Val Loss: 0.0262, Test Loss: 0.0307\n",
      "Epoch 128/500, Train Loss: 0.2016, Val Loss: 0.0249, Test Loss: 0.0300\n",
      "Epoch 129/500, Train Loss: 0.2195, Val Loss: 0.0243, Test Loss: 0.0299\n",
      "Epoch 130/500, Train Loss: 0.2087, Val Loss: 0.0235, Test Loss: 0.0294\n",
      "Epoch 131/500, Train Loss: 0.2127, Val Loss: 0.0236, Test Loss: 0.0295\n",
      "Epoch 132/500, Train Loss: 0.2199, Val Loss: 0.0239, Test Loss: 0.0297\n",
      "Epoch 133/500, Train Loss: 0.2215, Val Loss: 0.0268, Test Loss: 0.0325\n",
      "Epoch 134/500, Train Loss: 0.1937, Val Loss: 0.0333, Test Loss: 0.0393\n",
      "Epoch 135/500, Train Loss: 0.1994, Val Loss: 0.0363, Test Loss: 0.0424\n",
      "Epoch 136/500, Train Loss: 0.2083, Val Loss: 0.0376, Test Loss: 0.0436\n",
      "Epoch 137/500, Train Loss: 0.2098, Val Loss: 0.0365, Test Loss: 0.0425\n",
      "Epoch 138/500, Train Loss: 0.1942, Val Loss: 0.0336, Test Loss: 0.0395\n",
      "Epoch 139/500, Train Loss: 0.2234, Val Loss: 0.0287, Test Loss: 0.0344\n",
      "Epoch 140/500, Train Loss: 0.2011, Val Loss: 0.0256, Test Loss: 0.0313\n",
      "Epoch 141/500, Train Loss: 0.1783, Val Loss: 0.0230, Test Loss: 0.0286\n",
      "Epoch 142/500, Train Loss: 0.1851, Val Loss: 0.0218, Test Loss: 0.0273\n",
      "Epoch 143/500, Train Loss: 0.2079, Val Loss: 0.0197, Test Loss: 0.0252\n",
      "Epoch 144/500, Train Loss: 0.1939, Val Loss: 0.0188, Test Loss: 0.0245\n",
      "Epoch 145/500, Train Loss: 0.2121, Val Loss: 0.0191, Test Loss: 0.0248\n",
      "Epoch 146/500, Train Loss: 0.1887, Val Loss: 0.0204, Test Loss: 0.0259\n",
      "Epoch 147/500, Train Loss: 0.1797, Val Loss: 0.0252, Test Loss: 0.0302\n",
      "Epoch 148/500, Train Loss: 0.1986, Val Loss: 0.0324, Test Loss: 0.0364\n",
      "Epoch 149/500, Train Loss: 0.1806, Val Loss: 0.0356, Test Loss: 0.0388\n",
      "Epoch 150/500, Train Loss: 0.1702, Val Loss: 0.0350, Test Loss: 0.0379\n",
      "Epoch 151/500, Train Loss: 0.2057, Val Loss: 0.0322, Test Loss: 0.0350\n",
      "Epoch 152/500, Train Loss: 0.1671, Val Loss: 0.0280, Test Loss: 0.0310\n",
      "Epoch 153/500, Train Loss: 0.1810, Val Loss: 0.0247, Test Loss: 0.0278\n",
      "Epoch 154/500, Train Loss: 0.1789, Val Loss: 0.0221, Test Loss: 0.0254\n",
      "Epoch 155/500, Train Loss: 0.1750, Val Loss: 0.0211, Test Loss: 0.0244\n",
      "Epoch 156/500, Train Loss: 0.1791, Val Loss: 0.0207, Test Loss: 0.0239\n",
      "Epoch 157/500, Train Loss: 0.1829, Val Loss: 0.0198, Test Loss: 0.0232\n",
      "Epoch 158/500, Train Loss: 0.1813, Val Loss: 0.0190, Test Loss: 0.0226\n",
      "Epoch 159/500, Train Loss: 0.1923, Val Loss: 0.0183, Test Loss: 0.0222\n",
      "Epoch 160/500, Train Loss: 0.1625, Val Loss: 0.0190, Test Loss: 0.0227\n",
      "Epoch 161/500, Train Loss: 0.1550, Val Loss: 0.0196, Test Loss: 0.0233\n",
      "Epoch 162/500, Train Loss: 0.1980, Val Loss: 0.0204, Test Loss: 0.0242\n",
      "Epoch 163/500, Train Loss: 0.1553, Val Loss: 0.0214, Test Loss: 0.0251\n",
      "Epoch 164/500, Train Loss: 0.1643, Val Loss: 0.0232, Test Loss: 0.0268\n",
      "Epoch 165/500, Train Loss: 0.1788, Val Loss: 0.0249, Test Loss: 0.0284\n",
      "Epoch 166/500, Train Loss: 0.1559, Val Loss: 0.0260, Test Loss: 0.0293\n",
      "Epoch 167/500, Train Loss: 0.1680, Val Loss: 0.0268, Test Loss: 0.0299\n",
      "Epoch 168/500, Train Loss: 0.1550, Val Loss: 0.0270, Test Loss: 0.0301\n",
      "Epoch 169/500, Train Loss: 0.1425, Val Loss: 0.0252, Test Loss: 0.0285\n",
      "Epoch 170/500, Train Loss: 0.1629, Val Loss: 0.0243, Test Loss: 0.0279\n",
      "Epoch 171/500, Train Loss: 0.1561, Val Loss: 0.0209, Test Loss: 0.0251\n",
      "Epoch 172/500, Train Loss: 0.1582, Val Loss: 0.0186, Test Loss: 0.0232\n",
      "Epoch 173/500, Train Loss: 0.1672, Val Loss: 0.0170, Test Loss: 0.0219\n",
      "Epoch 174/500, Train Loss: 0.1509, Val Loss: 0.0180, Test Loss: 0.0228\n",
      "Epoch 175/500, Train Loss: 0.1520, Val Loss: 0.0202, Test Loss: 0.0249\n",
      "Epoch 176/500, Train Loss: 0.1438, Val Loss: 0.0215, Test Loss: 0.0263\n",
      "Epoch 177/500, Train Loss: 0.1604, Val Loss: 0.0230, Test Loss: 0.0278\n",
      "Epoch 178/500, Train Loss: 0.1505, Val Loss: 0.0258, Test Loss: 0.0306\n",
      "Epoch 179/500, Train Loss: 0.1586, Val Loss: 0.0279, Test Loss: 0.0326\n",
      "Epoch 180/500, Train Loss: 0.1528, Val Loss: 0.0276, Test Loss: 0.0323\n",
      "Epoch 181/500, Train Loss: 0.1745, Val Loss: 0.0253, Test Loss: 0.0301\n",
      "Epoch 182/500, Train Loss: 0.1534, Val Loss: 0.0226, Test Loss: 0.0276\n",
      "Epoch 183/500, Train Loss: 0.1696, Val Loss: 0.0196, Test Loss: 0.0250\n",
      "Epoch 184/500, Train Loss: 0.1473, Val Loss: 0.0173, Test Loss: 0.0230\n",
      "Epoch 185/500, Train Loss: 0.1464, Val Loss: 0.0180, Test Loss: 0.0236\n",
      "Epoch 186/500, Train Loss: 0.1710, Val Loss: 0.0186, Test Loss: 0.0240\n",
      "Epoch 187/500, Train Loss: 0.1382, Val Loss: 0.0196, Test Loss: 0.0246\n",
      "Epoch 188/500, Train Loss: 0.1683, Val Loss: 0.0209, Test Loss: 0.0255\n",
      "Epoch 189/500, Train Loss: 0.1693, Val Loss: 0.0210, Test Loss: 0.0255\n",
      "Epoch 190/500, Train Loss: 0.1504, Val Loss: 0.0215, Test Loss: 0.0259\n",
      "Epoch 191/500, Train Loss: 0.1486, Val Loss: 0.0215, Test Loss: 0.0258\n",
      "Epoch 192/500, Train Loss: 0.1437, Val Loss: 0.0221, Test Loss: 0.0261\n",
      "Epoch 193/500, Train Loss: 0.1369, Val Loss: 0.0227, Test Loss: 0.0265\n",
      "Epoch 194/500, Train Loss: 0.1460, Val Loss: 0.0231, Test Loss: 0.0269\n",
      "Epoch 195/500, Train Loss: 0.1415, Val Loss: 0.0235, Test Loss: 0.0272\n",
      "Epoch 196/500, Train Loss: 0.1521, Val Loss: 0.0220, Test Loss: 0.0260\n",
      "Epoch 197/500, Train Loss: 0.1267, Val Loss: 0.0205, Test Loss: 0.0246\n",
      "Epoch 198/500, Train Loss: 0.1494, Val Loss: 0.0190, Test Loss: 0.0233\n",
      "Epoch 199/500, Train Loss: 0.1372, Val Loss: 0.0178, Test Loss: 0.0223\n",
      "Epoch 200/500, Train Loss: 0.1301, Val Loss: 0.0178, Test Loss: 0.0223\n",
      "Epoch 201/500, Train Loss: 0.1396, Val Loss: 0.0174, Test Loss: 0.0219\n",
      "Epoch 202/500, Train Loss: 0.1271, Val Loss: 0.0169, Test Loss: 0.0213\n",
      "Epoch 203/500, Train Loss: 0.1483, Val Loss: 0.0175, Test Loss: 0.0218\n",
      "Epoch 204/500, Train Loss: 0.1518, Val Loss: 0.0201, Test Loss: 0.0239\n",
      "Epoch 205/500, Train Loss: 0.1293, Val Loss: 0.0225, Test Loss: 0.0259\n",
      "Epoch 206/500, Train Loss: 0.1334, Val Loss: 0.0219, Test Loss: 0.0255\n",
      "Epoch 207/500, Train Loss: 0.1286, Val Loss: 0.0214, Test Loss: 0.0250\n",
      "Epoch 208/500, Train Loss: 0.1442, Val Loss: 0.0189, Test Loss: 0.0229\n",
      "Epoch 209/500, Train Loss: 0.1262, Val Loss: 0.0163, Test Loss: 0.0208\n",
      "Epoch 210/500, Train Loss: 0.1315, Val Loss: 0.0147, Test Loss: 0.0195\n",
      "Epoch 211/500, Train Loss: 0.1329, Val Loss: 0.0144, Test Loss: 0.0192\n",
      "Epoch 212/500, Train Loss: 0.1274, Val Loss: 0.0146, Test Loss: 0.0192\n",
      "Epoch 213/500, Train Loss: 0.1399, Val Loss: 0.0160, Test Loss: 0.0201\n",
      "Epoch 214/500, Train Loss: 0.1328, Val Loss: 0.0185, Test Loss: 0.0221\n",
      "Epoch 215/500, Train Loss: 0.1207, Val Loss: 0.0205, Test Loss: 0.0238\n",
      "Epoch 216/500, Train Loss: 0.1262, Val Loss: 0.0218, Test Loss: 0.0248\n",
      "Epoch 217/500, Train Loss: 0.1119, Val Loss: 0.0215, Test Loss: 0.0246\n",
      "Epoch 218/500, Train Loss: 0.1247, Val Loss: 0.0229, Test Loss: 0.0257\n",
      "Epoch 219/500, Train Loss: 0.1201, Val Loss: 0.0234, Test Loss: 0.0260\n",
      "Epoch 220/500, Train Loss: 0.1155, Val Loss: 0.0247, Test Loss: 0.0271\n",
      "Epoch 221/500, Train Loss: 0.1313, Val Loss: 0.0228, Test Loss: 0.0256\n",
      "Epoch 222/500, Train Loss: 0.1182, Val Loss: 0.0202, Test Loss: 0.0235\n",
      "Epoch 223/500, Train Loss: 0.1325, Val Loss: 0.0174, Test Loss: 0.0214\n",
      "Epoch 224/500, Train Loss: 0.1259, Val Loss: 0.0156, Test Loss: 0.0202\n",
      "Epoch 225/500, Train Loss: 0.1293, Val Loss: 0.0149, Test Loss: 0.0197\n",
      "Epoch 226/500, Train Loss: 0.1338, Val Loss: 0.0158, Test Loss: 0.0204\n",
      "Epoch 227/500, Train Loss: 0.1231, Val Loss: 0.0184, Test Loss: 0.0225\n",
      "Epoch 228/500, Train Loss: 0.1166, Val Loss: 0.0225, Test Loss: 0.0259\n",
      "Epoch 229/500, Train Loss: 0.1251, Val Loss: 0.0261, Test Loss: 0.0290\n",
      "Epoch 230/500, Train Loss: 0.1338, Val Loss: 0.0249, Test Loss: 0.0281\n",
      "Epoch 231/500, Train Loss: 0.1126, Val Loss: 0.0218, Test Loss: 0.0255\n",
      "Epoch 232/500, Train Loss: 0.1130, Val Loss: 0.0195, Test Loss: 0.0237\n",
      "Epoch 233/500, Train Loss: 0.1144, Val Loss: 0.0169, Test Loss: 0.0215\n",
      "Epoch 234/500, Train Loss: 0.1150, Val Loss: 0.0157, Test Loss: 0.0205\n",
      "Epoch 235/500, Train Loss: 0.1190, Val Loss: 0.0147, Test Loss: 0.0198\n",
      "Epoch 236/500, Train Loss: 0.1087, Val Loss: 0.0143, Test Loss: 0.0195\n",
      "Epoch 237/500, Train Loss: 0.1231, Val Loss: 0.0144, Test Loss: 0.0197\n",
      "Epoch 238/500, Train Loss: 0.1175, Val Loss: 0.0145, Test Loss: 0.0199\n",
      "Epoch 239/500, Train Loss: 0.1188, Val Loss: 0.0155, Test Loss: 0.0210\n",
      "Epoch 240/500, Train Loss: 0.1124, Val Loss: 0.0181, Test Loss: 0.0233\n",
      "Epoch 241/500, Train Loss: 0.1078, Val Loss: 0.0227, Test Loss: 0.0276\n",
      "Epoch 242/500, Train Loss: 0.1056, Val Loss: 0.0263, Test Loss: 0.0310\n",
      "Epoch 243/500, Train Loss: 0.1202, Val Loss: 0.0278, Test Loss: 0.0325\n",
      "Epoch 244/500, Train Loss: 0.1109, Val Loss: 0.0240, Test Loss: 0.0289\n",
      "Epoch 245/500, Train Loss: 0.1236, Val Loss: 0.0188, Test Loss: 0.0242\n",
      "Epoch 246/500, Train Loss: 0.1065, Val Loss: 0.0155, Test Loss: 0.0211\n",
      "Epoch 247/500, Train Loss: 0.1112, Val Loss: 0.0129, Test Loss: 0.0189\n",
      "Epoch 248/500, Train Loss: 0.1029, Val Loss: 0.0122, Test Loss: 0.0183\n",
      "Epoch 249/500, Train Loss: 0.1118, Val Loss: 0.0124, Test Loss: 0.0183\n",
      "Epoch 250/500, Train Loss: 0.1117, Val Loss: 0.0140, Test Loss: 0.0195\n",
      "Epoch 251/500, Train Loss: 0.1005, Val Loss: 0.0178, Test Loss: 0.0227\n",
      "Epoch 252/500, Train Loss: 0.0994, Val Loss: 0.0223, Test Loss: 0.0268\n",
      "Epoch 253/500, Train Loss: 0.1149, Val Loss: 0.0249, Test Loss: 0.0293\n",
      "Epoch 254/500, Train Loss: 0.1027, Val Loss: 0.0255, Test Loss: 0.0298\n",
      "Epoch 255/500, Train Loss: 0.1114, Val Loss: 0.0227, Test Loss: 0.0271\n",
      "Epoch 256/500, Train Loss: 0.1072, Val Loss: 0.0193, Test Loss: 0.0238\n",
      "Epoch 257/500, Train Loss: 0.0942, Val Loss: 0.0167, Test Loss: 0.0213\n",
      "Epoch 258/500, Train Loss: 0.1024, Val Loss: 0.0151, Test Loss: 0.0198\n",
      "Epoch 259/500, Train Loss: 0.0981, Val Loss: 0.0146, Test Loss: 0.0193\n",
      "Epoch 260/500, Train Loss: 0.1016, Val Loss: 0.0144, Test Loss: 0.0191\n",
      "Epoch 261/500, Train Loss: 0.1027, Val Loss: 0.0148, Test Loss: 0.0193\n",
      "Epoch 262/500, Train Loss: 0.1102, Val Loss: 0.0153, Test Loss: 0.0197\n",
      "Epoch 263/500, Train Loss: 0.1010, Val Loss: 0.0168, Test Loss: 0.0207\n",
      "Epoch 264/500, Train Loss: 0.1093, Val Loss: 0.0174, Test Loss: 0.0211\n",
      "Epoch 265/500, Train Loss: 0.0940, Val Loss: 0.0196, Test Loss: 0.0228\n",
      "Epoch 266/500, Train Loss: 0.0971, Val Loss: 0.0202, Test Loss: 0.0233\n",
      "Epoch 267/500, Train Loss: 0.0944, Val Loss: 0.0202, Test Loss: 0.0233\n",
      "Epoch 268/500, Train Loss: 0.0934, Val Loss: 0.0187, Test Loss: 0.0219\n",
      "Epoch 269/500, Train Loss: 0.1034, Val Loss: 0.0178, Test Loss: 0.0212\n",
      "Epoch 270/500, Train Loss: 0.0924, Val Loss: 0.0170, Test Loss: 0.0205\n",
      "Epoch 271/500, Train Loss: 0.1042, Val Loss: 0.0170, Test Loss: 0.0204\n",
      "Epoch 272/500, Train Loss: 0.1003, Val Loss: 0.0175, Test Loss: 0.0206\n",
      "Epoch 273/500, Train Loss: 0.1079, Val Loss: 0.0186, Test Loss: 0.0214\n",
      "Epoch 274/500, Train Loss: 0.0937, Val Loss: 0.0194, Test Loss: 0.0221\n",
      "Epoch 275/500, Train Loss: 0.0962, Val Loss: 0.0182, Test Loss: 0.0213\n",
      "Epoch 276/500, Train Loss: 0.1042, Val Loss: 0.0174, Test Loss: 0.0207\n",
      "Epoch 277/500, Train Loss: 0.0909, Val Loss: 0.0167, Test Loss: 0.0203\n",
      "Epoch 278/500, Train Loss: 0.0959, Val Loss: 0.0157, Test Loss: 0.0195\n",
      "Epoch 279/500, Train Loss: 0.0935, Val Loss: 0.0143, Test Loss: 0.0187\n",
      "Epoch 280/500, Train Loss: 0.0945, Val Loss: 0.0137, Test Loss: 0.0183\n",
      "Epoch 281/500, Train Loss: 0.1032, Val Loss: 0.0132, Test Loss: 0.0179\n",
      "Epoch 282/500, Train Loss: 0.0899, Val Loss: 0.0132, Test Loss: 0.0179\n",
      "Epoch 283/500, Train Loss: 0.0959, Val Loss: 0.0141, Test Loss: 0.0186\n",
      "Epoch 284/500, Train Loss: 0.0863, Val Loss: 0.0148, Test Loss: 0.0192\n",
      "Epoch 285/500, Train Loss: 0.0892, Val Loss: 0.0154, Test Loss: 0.0198\n",
      "Epoch 286/500, Train Loss: 0.0811, Val Loss: 0.0161, Test Loss: 0.0204\n",
      "Epoch 287/500, Train Loss: 0.0849, Val Loss: 0.0165, Test Loss: 0.0207\n",
      "Epoch 288/500, Train Loss: 0.0860, Val Loss: 0.0163, Test Loss: 0.0206\n",
      "Epoch 289/500, Train Loss: 0.0911, Val Loss: 0.0164, Test Loss: 0.0207\n",
      "Epoch 290/500, Train Loss: 0.0940, Val Loss: 0.0153, Test Loss: 0.0198\n",
      "Epoch 291/500, Train Loss: 0.0862, Val Loss: 0.0146, Test Loss: 0.0193\n",
      "Epoch 292/500, Train Loss: 0.0922, Val Loss: 0.0140, Test Loss: 0.0188\n",
      "Epoch 293/500, Train Loss: 0.0873, Val Loss: 0.0136, Test Loss: 0.0185\n",
      "Epoch 294/500, Train Loss: 0.0934, Val Loss: 0.0137, Test Loss: 0.0187\n",
      "Epoch 295/500, Train Loss: 0.0934, Val Loss: 0.0145, Test Loss: 0.0194\n",
      "Epoch 296/500, Train Loss: 0.0931, Val Loss: 0.0150, Test Loss: 0.0199\n",
      "Epoch 297/500, Train Loss: 0.0746, Val Loss: 0.0157, Test Loss: 0.0205\n",
      "Epoch 298/500, Train Loss: 0.0954, Val Loss: 0.0156, Test Loss: 0.0205\n",
      "Epoch 299/500, Train Loss: 0.0900, Val Loss: 0.0154, Test Loss: 0.0203\n",
      "Epoch 300/500, Train Loss: 0.0917, Val Loss: 0.0158, Test Loss: 0.0207\n",
      "Epoch 301/500, Train Loss: 0.0830, Val Loss: 0.0168, Test Loss: 0.0216\n",
      "Epoch 302/500, Train Loss: 0.0852, Val Loss: 0.0182, Test Loss: 0.0230\n",
      "Epoch 303/500, Train Loss: 0.0862, Val Loss: 0.0182, Test Loss: 0.0230\n",
      "Epoch 304/500, Train Loss: 0.0849, Val Loss: 0.0181, Test Loss: 0.0230\n",
      "Epoch 305/500, Train Loss: 0.0816, Val Loss: 0.0167, Test Loss: 0.0217\n",
      "Epoch 306/500, Train Loss: 0.0888, Val Loss: 0.0152, Test Loss: 0.0202\n",
      "Epoch 307/500, Train Loss: 0.0942, Val Loss: 0.0138, Test Loss: 0.0189\n",
      "Epoch 308/500, Train Loss: 0.0772, Val Loss: 0.0128, Test Loss: 0.0180\n",
      "Epoch 309/500, Train Loss: 0.0787, Val Loss: 0.0124, Test Loss: 0.0176\n",
      "Epoch 310/500, Train Loss: 0.0856, Val Loss: 0.0129, Test Loss: 0.0179\n",
      "Epoch 311/500, Train Loss: 0.0861, Val Loss: 0.0143, Test Loss: 0.0190\n",
      "Epoch 312/500, Train Loss: 0.0819, Val Loss: 0.0171, Test Loss: 0.0214\n",
      "Epoch 313/500, Train Loss: 0.0780, Val Loss: 0.0196, Test Loss: 0.0236\n",
      "Epoch 314/500, Train Loss: 0.0905, Val Loss: 0.0202, Test Loss: 0.0240\n",
      "Epoch 315/500, Train Loss: 0.0848, Val Loss: 0.0194, Test Loss: 0.0231\n",
      "Epoch 316/500, Train Loss: 0.0917, Val Loss: 0.0174, Test Loss: 0.0211\n",
      "Epoch 317/500, Train Loss: 0.0782, Val Loss: 0.0155, Test Loss: 0.0193\n",
      "Epoch 318/500, Train Loss: 0.0750, Val Loss: 0.0140, Test Loss: 0.0181\n",
      "Epoch 319/500, Train Loss: 0.0798, Val Loss: 0.0128, Test Loss: 0.0172\n",
      "Epoch 320/500, Train Loss: 0.0813, Val Loss: 0.0123, Test Loss: 0.0170\n",
      "Epoch 321/500, Train Loss: 0.0719, Val Loss: 0.0118, Test Loss: 0.0168\n",
      "Epoch 322/500, Train Loss: 0.0910, Val Loss: 0.0119, Test Loss: 0.0169\n",
      "Epoch 323/500, Train Loss: 0.0810, Val Loss: 0.0129, Test Loss: 0.0174\n",
      "Epoch 324/500, Train Loss: 0.0788, Val Loss: 0.0149, Test Loss: 0.0189\n",
      "Epoch 325/500, Train Loss: 0.0857, Val Loss: 0.0178, Test Loss: 0.0213\n",
      "Epoch 326/500, Train Loss: 0.0788, Val Loss: 0.0205, Test Loss: 0.0237\n",
      "Epoch 327/500, Train Loss: 0.0907, Val Loss: 0.0217, Test Loss: 0.0248\n",
      "Epoch 328/500, Train Loss: 0.0803, Val Loss: 0.0205, Test Loss: 0.0239\n",
      "Epoch 329/500, Train Loss: 0.0725, Val Loss: 0.0178, Test Loss: 0.0216\n",
      "Epoch 330/500, Train Loss: 0.0779, Val Loss: 0.0152, Test Loss: 0.0196\n",
      "Epoch 331/500, Train Loss: 0.0798, Val Loss: 0.0136, Test Loss: 0.0184\n",
      "Epoch 332/500, Train Loss: 0.0767, Val Loss: 0.0128, Test Loss: 0.0180\n",
      "Epoch 333/500, Train Loss: 0.0684, Val Loss: 0.0125, Test Loss: 0.0180\n",
      "Epoch 334/500, Train Loss: 0.0822, Val Loss: 0.0130, Test Loss: 0.0183\n",
      "Epoch 335/500, Train Loss: 0.0672, Val Loss: 0.0140, Test Loss: 0.0189\n",
      "Epoch 336/500, Train Loss: 0.0690, Val Loss: 0.0154, Test Loss: 0.0200\n",
      "Epoch 337/500, Train Loss: 0.0760, Val Loss: 0.0173, Test Loss: 0.0215\n",
      "Epoch 338/500, Train Loss: 0.0763, Val Loss: 0.0174, Test Loss: 0.0217\n",
      "Epoch 339/500, Train Loss: 0.0747, Val Loss: 0.0170, Test Loss: 0.0213\n",
      "Epoch 340/500, Train Loss: 0.0752, Val Loss: 0.0168, Test Loss: 0.0210\n",
      "Epoch 341/500, Train Loss: 0.0699, Val Loss: 0.0158, Test Loss: 0.0201\n",
      "Epoch 342/500, Train Loss: 0.0708, Val Loss: 0.0148, Test Loss: 0.0191\n",
      "Epoch 343/500, Train Loss: 0.0699, Val Loss: 0.0136, Test Loss: 0.0182\n",
      "Epoch 344/500, Train Loss: 0.0737, Val Loss: 0.0134, Test Loss: 0.0180\n",
      "Epoch 345/500, Train Loss: 0.0704, Val Loss: 0.0135, Test Loss: 0.0180\n",
      "Epoch 346/500, Train Loss: 0.0755, Val Loss: 0.0142, Test Loss: 0.0185\n",
      "Epoch 347/500, Train Loss: 0.0675, Val Loss: 0.0155, Test Loss: 0.0194\n",
      "Epoch 348/500, Train Loss: 0.0803, Val Loss: 0.0162, Test Loss: 0.0200\n",
      "Epoch 349/500, Train Loss: 0.0697, Val Loss: 0.0165, Test Loss: 0.0203\n",
      "Epoch 350/500, Train Loss: 0.0616, Val Loss: 0.0162, Test Loss: 0.0200\n",
      "Epoch 351/500, Train Loss: 0.0624, Val Loss: 0.0157, Test Loss: 0.0196\n",
      "Epoch 352/500, Train Loss: 0.0731, Val Loss: 0.0151, Test Loss: 0.0191\n",
      "Epoch 353/500, Train Loss: 0.0706, Val Loss: 0.0146, Test Loss: 0.0188\n",
      "Epoch 354/500, Train Loss: 0.0728, Val Loss: 0.0142, Test Loss: 0.0186\n",
      "Epoch 355/500, Train Loss: 0.0608, Val Loss: 0.0138, Test Loss: 0.0183\n",
      "Epoch 356/500, Train Loss: 0.0680, Val Loss: 0.0141, Test Loss: 0.0186\n",
      "Epoch 357/500, Train Loss: 0.0642, Val Loss: 0.0144, Test Loss: 0.0189\n",
      "Epoch 358/500, Train Loss: 0.0694, Val Loss: 0.0146, Test Loss: 0.0190\n",
      "Epoch 359/500, Train Loss: 0.0657, Val Loss: 0.0145, Test Loss: 0.0190\n",
      "Epoch 360/500, Train Loss: 0.0628, Val Loss: 0.0149, Test Loss: 0.0194\n",
      "Epoch 361/500, Train Loss: 0.0663, Val Loss: 0.0152, Test Loss: 0.0197\n",
      "Epoch 362/500, Train Loss: 0.0688, Val Loss: 0.0155, Test Loss: 0.0200\n",
      "Epoch 363/500, Train Loss: 0.0642, Val Loss: 0.0154, Test Loss: 0.0199\n",
      "Epoch 364/500, Train Loss: 0.0650, Val Loss: 0.0159, Test Loss: 0.0204\n",
      "Epoch 365/500, Train Loss: 0.0669, Val Loss: 0.0158, Test Loss: 0.0203\n",
      "Epoch 366/500, Train Loss: 0.0574, Val Loss: 0.0148, Test Loss: 0.0195\n",
      "Epoch 367/500, Train Loss: 0.0626, Val Loss: 0.0143, Test Loss: 0.0193\n",
      "Epoch 368/500, Train Loss: 0.0638, Val Loss: 0.0139, Test Loss: 0.0190\n",
      "Epoch 369/500, Train Loss: 0.0654, Val Loss: 0.0138, Test Loss: 0.0189\n",
      "Epoch 370/500, Train Loss: 0.0700, Val Loss: 0.0142, Test Loss: 0.0192\n",
      "Epoch 371/500, Train Loss: 0.0657, Val Loss: 0.0146, Test Loss: 0.0195\n",
      "Epoch 372/500, Train Loss: 0.0636, Val Loss: 0.0151, Test Loss: 0.0199\n",
      "Epoch 373/500, Train Loss: 0.0632, Val Loss: 0.0157, Test Loss: 0.0203\n",
      "Epoch 374/500, Train Loss: 0.0672, Val Loss: 0.0158, Test Loss: 0.0204\n",
      "Epoch 375/500, Train Loss: 0.0673, Val Loss: 0.0165, Test Loss: 0.0208\n",
      "Epoch 376/500, Train Loss: 0.0646, Val Loss: 0.0167, Test Loss: 0.0209\n",
      "Epoch 377/500, Train Loss: 0.0595, Val Loss: 0.0161, Test Loss: 0.0204\n",
      "Epoch 378/500, Train Loss: 0.0705, Val Loss: 0.0156, Test Loss: 0.0200\n",
      "Epoch 379/500, Train Loss: 0.0686, Val Loss: 0.0149, Test Loss: 0.0194\n",
      "Epoch 380/500, Train Loss: 0.0597, Val Loss: 0.0149, Test Loss: 0.0194\n",
      "Epoch 381/500, Train Loss: 0.0643, Val Loss: 0.0145, Test Loss: 0.0191\n",
      "Epoch 382/500, Train Loss: 0.0620, Val Loss: 0.0142, Test Loss: 0.0188\n",
      "Epoch 383/500, Train Loss: 0.0646, Val Loss: 0.0142, Test Loss: 0.0189\n",
      "Epoch 384/500, Train Loss: 0.0665, Val Loss: 0.0143, Test Loss: 0.0191\n",
      "Epoch 385/500, Train Loss: 0.0680, Val Loss: 0.0144, Test Loss: 0.0192\n",
      "Epoch 386/500, Train Loss: 0.0627, Val Loss: 0.0145, Test Loss: 0.0193\n",
      "Epoch 387/500, Train Loss: 0.0614, Val Loss: 0.0145, Test Loss: 0.0194\n",
      "Epoch 388/500, Train Loss: 0.0653, Val Loss: 0.0149, Test Loss: 0.0198\n",
      "Epoch 389/500, Train Loss: 0.0590, Val Loss: 0.0147, Test Loss: 0.0197\n",
      "Epoch 390/500, Train Loss: 0.0629, Val Loss: 0.0144, Test Loss: 0.0195\n",
      "Epoch 391/500, Train Loss: 0.0577, Val Loss: 0.0146, Test Loss: 0.0197\n",
      "Epoch 392/500, Train Loss: 0.0611, Val Loss: 0.0146, Test Loss: 0.0197\n",
      "Epoch 393/500, Train Loss: 0.0668, Val Loss: 0.0143, Test Loss: 0.0194\n",
      "Epoch 394/500, Train Loss: 0.0672, Val Loss: 0.0142, Test Loss: 0.0192\n",
      "Epoch 395/500, Train Loss: 0.0630, Val Loss: 0.0145, Test Loss: 0.0195\n",
      "Epoch 396/500, Train Loss: 0.0643, Val Loss: 0.0142, Test Loss: 0.0191\n",
      "Epoch 397/500, Train Loss: 0.0654, Val Loss: 0.0137, Test Loss: 0.0187\n",
      "Epoch 398/500, Train Loss: 0.0615, Val Loss: 0.0135, Test Loss: 0.0185\n",
      "Epoch 399/500, Train Loss: 0.0580, Val Loss: 0.0139, Test Loss: 0.0188\n",
      "Epoch 400/500, Train Loss: 0.0621, Val Loss: 0.0137, Test Loss: 0.0187\n",
      "Epoch 401/500, Train Loss: 0.0629, Val Loss: 0.0140, Test Loss: 0.0190\n",
      "Epoch 402/500, Train Loss: 0.0652, Val Loss: 0.0145, Test Loss: 0.0194\n",
      "Epoch 403/500, Train Loss: 0.0569, Val Loss: 0.0151, Test Loss: 0.0199\n",
      "Epoch 404/500, Train Loss: 0.0647, Val Loss: 0.0154, Test Loss: 0.0203\n",
      "Epoch 405/500, Train Loss: 0.0549, Val Loss: 0.0153, Test Loss: 0.0201\n",
      "Epoch 406/500, Train Loss: 0.0618, Val Loss: 0.0152, Test Loss: 0.0199\n",
      "Epoch 407/500, Train Loss: 0.0687, Val Loss: 0.0148, Test Loss: 0.0196\n",
      "Epoch 408/500, Train Loss: 0.0592, Val Loss: 0.0151, Test Loss: 0.0197\n",
      "Epoch 409/500, Train Loss: 0.0568, Val Loss: 0.0149, Test Loss: 0.0195\n",
      "Epoch 410/500, Train Loss: 0.0547, Val Loss: 0.0144, Test Loss: 0.0191\n",
      "Epoch 411/500, Train Loss: 0.0637, Val Loss: 0.0140, Test Loss: 0.0188\n",
      "Epoch 412/500, Train Loss: 0.0520, Val Loss: 0.0137, Test Loss: 0.0187\n",
      "Epoch 413/500, Train Loss: 0.0636, Val Loss: 0.0139, Test Loss: 0.0188\n",
      "Epoch 414/500, Train Loss: 0.0608, Val Loss: 0.0143, Test Loss: 0.0190\n",
      "Epoch 415/500, Train Loss: 0.0605, Val Loss: 0.0151, Test Loss: 0.0195\n",
      "Epoch 416/500, Train Loss: 0.0556, Val Loss: 0.0163, Test Loss: 0.0204\n",
      "Epoch 417/500, Train Loss: 0.0574, Val Loss: 0.0171, Test Loss: 0.0210\n",
      "Epoch 418/500, Train Loss: 0.0566, Val Loss: 0.0173, Test Loss: 0.0212\n",
      "Epoch 419/500, Train Loss: 0.0593, Val Loss: 0.0161, Test Loss: 0.0202\n",
      "Epoch 420/500, Train Loss: 0.0608, Val Loss: 0.0148, Test Loss: 0.0193\n",
      "Epoch 421/500, Train Loss: 0.0610, Val Loss: 0.0139, Test Loss: 0.0187\n",
      "Epoch 422/500, Train Loss: 0.0553, Val Loss: 0.0134, Test Loss: 0.0184\n",
      "Epoch 423/500, Train Loss: 0.0555, Val Loss: 0.0132, Test Loss: 0.0182\n",
      "Epoch 424/500, Train Loss: 0.0673, Val Loss: 0.0131, Test Loss: 0.0180\n",
      "Epoch 425/500, Train Loss: 0.0621, Val Loss: 0.0133, Test Loss: 0.0180\n",
      "Epoch 426/500, Train Loss: 0.0582, Val Loss: 0.0136, Test Loss: 0.0180\n",
      "Epoch 427/500, Train Loss: 0.0591, Val Loss: 0.0142, Test Loss: 0.0183\n",
      "Epoch 428/500, Train Loss: 0.0511, Val Loss: 0.0154, Test Loss: 0.0191\n",
      "Epoch 429/500, Train Loss: 0.0480, Val Loss: 0.0165, Test Loss: 0.0198\n",
      "Epoch 430/500, Train Loss: 0.0568, Val Loss: 0.0169, Test Loss: 0.0201\n",
      "Epoch 431/500, Train Loss: 0.0532, Val Loss: 0.0165, Test Loss: 0.0197\n",
      "Epoch 432/500, Train Loss: 0.0642, Val Loss: 0.0153, Test Loss: 0.0188\n",
      "Epoch 433/500, Train Loss: 0.0537, Val Loss: 0.0143, Test Loss: 0.0181\n",
      "Epoch 434/500, Train Loss: 0.0576, Val Loss: 0.0132, Test Loss: 0.0173\n",
      "Epoch 435/500, Train Loss: 0.0549, Val Loss: 0.0125, Test Loss: 0.0169\n",
      "Epoch 436/500, Train Loss: 0.0580, Val Loss: 0.0125, Test Loss: 0.0170\n",
      "Epoch 437/500, Train Loss: 0.0512, Val Loss: 0.0129, Test Loss: 0.0172\n",
      "Epoch 438/500, Train Loss: 0.0546, Val Loss: 0.0130, Test Loss: 0.0174\n",
      "Epoch 439/500, Train Loss: 0.0529, Val Loss: 0.0137, Test Loss: 0.0179\n",
      "Epoch 440/500, Train Loss: 0.0499, Val Loss: 0.0149, Test Loss: 0.0187\n",
      "Epoch 441/500, Train Loss: 0.0531, Val Loss: 0.0157, Test Loss: 0.0194\n",
      "Epoch 442/500, Train Loss: 0.0572, Val Loss: 0.0160, Test Loss: 0.0197\n",
      "Epoch 443/500, Train Loss: 0.0551, Val Loss: 0.0152, Test Loss: 0.0192\n",
      "Epoch 444/500, Train Loss: 0.0545, Val Loss: 0.0140, Test Loss: 0.0184\n",
      "Epoch 445/500, Train Loss: 0.0546, Val Loss: 0.0136, Test Loss: 0.0182\n",
      "Epoch 446/500, Train Loss: 0.0558, Val Loss: 0.0137, Test Loss: 0.0183\n",
      "Epoch 447/500, Train Loss: 0.0544, Val Loss: 0.0139, Test Loss: 0.0185\n",
      "Epoch 448/500, Train Loss: 0.0488, Val Loss: 0.0144, Test Loss: 0.0190\n",
      "Epoch 449/500, Train Loss: 0.0514, Val Loss: 0.0155, Test Loss: 0.0198\n",
      "Epoch 450/500, Train Loss: 0.0535, Val Loss: 0.0164, Test Loss: 0.0205\n",
      "Epoch 451/500, Train Loss: 0.0511, Val Loss: 0.0169, Test Loss: 0.0209\n",
      "Epoch 452/500, Train Loss: 0.0578, Val Loss: 0.0174, Test Loss: 0.0214\n",
      "Epoch 453/500, Train Loss: 0.0528, Val Loss: 0.0175, Test Loss: 0.0215\n",
      "Epoch 454/500, Train Loss: 0.0531, Val Loss: 0.0171, Test Loss: 0.0211\n",
      "Epoch 455/500, Train Loss: 0.0536, Val Loss: 0.0155, Test Loss: 0.0198\n",
      "Epoch 456/500, Train Loss: 0.0564, Val Loss: 0.0144, Test Loss: 0.0189\n",
      "Epoch 457/500, Train Loss: 0.0525, Val Loss: 0.0135, Test Loss: 0.0183\n",
      "Epoch 458/500, Train Loss: 0.0472, Val Loss: 0.0130, Test Loss: 0.0180\n",
      "Epoch 459/500, Train Loss: 0.0510, Val Loss: 0.0130, Test Loss: 0.0179\n",
      "Epoch 460/500, Train Loss: 0.0521, Val Loss: 0.0134, Test Loss: 0.0182\n",
      "Epoch 461/500, Train Loss: 0.0551, Val Loss: 0.0145, Test Loss: 0.0189\n",
      "Epoch 462/500, Train Loss: 0.0534, Val Loss: 0.0156, Test Loss: 0.0198\n",
      "Epoch 463/500, Train Loss: 0.0520, Val Loss: 0.0167, Test Loss: 0.0208\n",
      "Epoch 464/500, Train Loss: 0.0516, Val Loss: 0.0169, Test Loss: 0.0209\n",
      "Epoch 465/500, Train Loss: 0.0488, Val Loss: 0.0162, Test Loss: 0.0203\n",
      "Epoch 466/500, Train Loss: 0.0500, Val Loss: 0.0154, Test Loss: 0.0197\n",
      "Epoch 467/500, Train Loss: 0.0474, Val Loss: 0.0142, Test Loss: 0.0187\n",
      "Epoch 468/500, Train Loss: 0.0523, Val Loss: 0.0132, Test Loss: 0.0180\n",
      "Epoch 469/500, Train Loss: 0.0498, Val Loss: 0.0128, Test Loss: 0.0177\n",
      "Epoch 470/500, Train Loss: 0.0483, Val Loss: 0.0129, Test Loss: 0.0178\n",
      "Epoch 471/500, Train Loss: 0.0507, Val Loss: 0.0133, Test Loss: 0.0180\n",
      "Epoch 472/500, Train Loss: 0.0474, Val Loss: 0.0142, Test Loss: 0.0187\n",
      "Epoch 473/500, Train Loss: 0.0462, Val Loss: 0.0154, Test Loss: 0.0197\n",
      "Epoch 474/500, Train Loss: 0.0465, Val Loss: 0.0161, Test Loss: 0.0202\n",
      "Epoch 475/500, Train Loss: 0.0486, Val Loss: 0.0157, Test Loss: 0.0199\n",
      "Epoch 476/500, Train Loss: 0.0479, Val Loss: 0.0150, Test Loss: 0.0193\n",
      "Epoch 477/500, Train Loss: 0.0476, Val Loss: 0.0137, Test Loss: 0.0183\n",
      "Epoch 478/500, Train Loss: 0.0479, Val Loss: 0.0129, Test Loss: 0.0177\n",
      "Epoch 479/500, Train Loss: 0.0496, Val Loss: 0.0126, Test Loss: 0.0176\n",
      "Epoch 480/500, Train Loss: 0.0510, Val Loss: 0.0125, Test Loss: 0.0175\n",
      "Epoch 481/500, Train Loss: 0.0558, Val Loss: 0.0129, Test Loss: 0.0178\n",
      "Epoch 482/500, Train Loss: 0.0498, Val Loss: 0.0134, Test Loss: 0.0182\n",
      "Epoch 483/500, Train Loss: 0.0500, Val Loss: 0.0139, Test Loss: 0.0186\n",
      "Epoch 484/500, Train Loss: 0.0473, Val Loss: 0.0144, Test Loss: 0.0190\n",
      "Epoch 485/500, Train Loss: 0.0509, Val Loss: 0.0150, Test Loss: 0.0194\n",
      "Epoch 486/500, Train Loss: 0.0489, Val Loss: 0.0157, Test Loss: 0.0199\n",
      "Epoch 487/500, Train Loss: 0.0497, Val Loss: 0.0156, Test Loss: 0.0199\n",
      "Epoch 488/500, Train Loss: 0.0556, Val Loss: 0.0152, Test Loss: 0.0196\n",
      "Epoch 489/500, Train Loss: 0.0474, Val Loss: 0.0144, Test Loss: 0.0190\n",
      "Epoch 490/500, Train Loss: 0.0450, Val Loss: 0.0136, Test Loss: 0.0184\n",
      "Epoch 491/500, Train Loss: 0.0495, Val Loss: 0.0131, Test Loss: 0.0181\n",
      "Epoch 492/500, Train Loss: 0.0462, Val Loss: 0.0127, Test Loss: 0.0178\n",
      "Epoch 493/500, Train Loss: 0.0469, Val Loss: 0.0130, Test Loss: 0.0179\n",
      "Epoch 494/500, Train Loss: 0.0543, Val Loss: 0.0136, Test Loss: 0.0183\n",
      "Epoch 495/500, Train Loss: 0.0471, Val Loss: 0.0149, Test Loss: 0.0192\n",
      "Epoch 496/500, Train Loss: 0.0569, Val Loss: 0.0162, Test Loss: 0.0202\n",
      "Epoch 497/500, Train Loss: 0.0483, Val Loss: 0.0174, Test Loss: 0.0211\n",
      "Epoch 498/500, Train Loss: 0.0491, Val Loss: 0.0175, Test Loss: 0.0212\n",
      "Epoch 499/500, Train Loss: 0.0477, Val Loss: 0.0161, Test Loss: 0.0201\n",
      "Epoch 500/500, Train Loss: 0.0478, Val Loss: 0.0143, Test Loss: 0.0187\n"
     ]
    }
   ],
   "source": [
    "def train(model, graph, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out, log_probs = model(batch.x.float(), batch.edge_index)\n",
    "        if task == \"reg\":\n",
    "            y_pred = out\n",
    "        else: \n",
    "            y_pred = log_probs\n",
    "        y_true = batch.y.view(-1, 1)\n",
    "        loss = criterion(y_pred, y_true) #only compute the loss on the train nodes.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def test(model, graph, criterion, loader): #mask parameter added.\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            out, log_probs = model(batch.x.float(), batch.edge_index)\n",
    "            if task == \"reg\":\n",
    "                y_pred = out\n",
    "            else: \n",
    "                y_pred = log_probs\n",
    "            y_true = batch.y.view(-1, 1)\n",
    "            loss = criterion(y_pred, y_true) \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Training loop\n",
    "train_losses = []  # List to store losses\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "epochs_list = [] # List to store epoch numbers.\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, graph, optimizer, criterion)\n",
    "    val_loss = test(model, graph, criterion, val_loader) #pass the validation mask\n",
    "    test_loss = test(model, graph, criterion, test_loader) #pass the test mask\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    epochs_list.append(epoch + 1)\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACB1klEQVR4nO3dd3hUZf7+8feZmplUQkISIDTpvSNgQUEBFcXKuq6ia/mp4Ora9uu69nVZ17quXVdZXV3EAlYUREEpopTQQamhJISWnkwyc87vj0kmGRIQcJJAuF/XNdcmZ86ceeYkbm4+TzMsy7IQERERaSRsDd0AERERkUhSuBEREZFGReFGREREGhWFGxEREWlUFG5ERESkUVG4ERERkUZF4UZEREQaFYUbERERaVQUbkRERKRRUbgRERGRRkXhRkRqmDx5MoZhsHjx4oZuiojIEVO4ERERkUZF4UZE5CBM06S0tLShmyEiR0jhRkSO2rJlyxg9ejRxcXHExMQwfPhwvv/++7BzysvLeeihh+jQoQNRUVE0bdqUU045hVmzZoXOyc7O5pprrqFly5a43W7S0tK44IIL2LJlyy+2Yd26dVx22WUkJyfj8Xjo1KkT9957b+j5q6++mjZt2tR43YMPPohhGGHHDMNg4sSJvP3223Tr1g23280nn3xCYmIi11xzTY1r5OfnExUVxZ133hk65vP5eOCBB2jfvj1ut5v09HTuvvtufD5f2GtnzZrFKaecQkJCAjExMXTq1Ik///nPv/h5ReSXORq6ASJyfFq9ejWnnnoqcXFx3H333TidTl5++WWGDRvG3LlzGTRoEBAMEZMmTeK6665j4MCB5Ofns3jxYpYuXcpZZ50FwMUXX8zq1au55ZZbaNOmDTk5OcyaNYvMzMxag0mlFStWcOqpp+J0Ornhhhto06YNGzdu5JNPPuHRRx89qs/19ddfM3XqVCZOnEhSUhIdOnTgwgsv5MMPP+Tll1/G5XKFzp0+fTo+n4/f/OY3QLDSc/755zNv3jxuuOEGunTpwsqVK3n66af56aefmD59eujenXfeefTs2ZOHH34Yt9vNhg0bmD9//lG1WUQOYImIHOCNN96wAOvHH3886Dljx461XC6XtXHjxtCxnTt3WrGxsdZpp50WOtarVy/r3HPPPeh19u/fbwHW448/fsTtPO2006zY2Fhr69atYcdN0wx9PX78eKt169Y1XvvAAw9YB/5fIGDZbDZr9erVYce//PJLC7A++eSTsOPnnHOO1a5du9D3b731lmWz2azvvvsu7LyXXnrJAqz58+dblmVZTz/9tAVYu3fvPvwPKyKHTd1SInLEAoEAM2fOZOzYsbRr1y50PC0tjd/+9rfMmzeP/Px8ABISEli9ejU///xzrdfyeDy4XC7mzJnD/v37D7sNu3fv5ttvv+X3v/89rVq1CnvuwO6mI3H66afTtWvXsGNnnnkmSUlJvPvuu6Fj+/fvZ9asWYwbNy507L333qNLly507tyZPXv2hB5nnnkmAN988w0QvCcAH330EaZpHnVbRaR2CjcicsR2795NcXExnTp1qvFcly5dME2Tbdu2AfDwww+Tm5tLx44d6dGjB3fddRcrVqwIne92u3nssceYMWMGKSkpnHbaafzjH/8gOzv7kG3YtGkTAN27d4/gJ4O2bdvWOOZwOLj44ov56KOPQmNnPvzwQ8rLy8PCzc8//8zq1atJTk4Oe3Ts2BGAnJwcAMaNG8fQoUO57rrrSElJ4Te/+Q1Tp05V0BGJEIUbEalTp512Ghs3buT111+ne/fuvPbaa/Tt25fXXnstdM5tt93GTz/9xKRJk4iKiuK+++6jS5cuLFu27Fe//8GqOIFAoNbjHo+n1uO/+c1vKCgoYMaMGQBMnTqVzp0706tXr9A5pmnSo0cPZs2aVevj5ptvDr3Ht99+y1dffcWVV17JihUrGDduHGedddZB2yUiR6Ch+8VE5NjzS2Nu/H6/5fV6rcsuu6zGczfeeKNls9msvLy8Wl9bUFBg9enTx2rRosVB3/+nn36yvF6vdcUVVxz0nJycHAuwbr311kN+lj/+8Y9WfHx8jeNXXnllrWNuJkyYUOt1AoGAlZaWZv3mN7+xdu/ebTkcDuuBBx4IO+ecc86xWrRoETbm53A9+uijFmDNmjXriF8rIuFUuRGRI2a32zn77LP56KOPwqZr79q1i3feeYdTTjmFuLg4APbu3Rv22piYGNq3bx/q3ikuLq6xlsxJJ51EbGxsjenT1SUnJ3Paaafx+uuvk5mZGfacZVlh18rLywvrCsvKymLatGlH9JltNhuXXHIJn3zyCW+99RZ+vz+sSwrgsssuY8eOHbz66qs1Xl9SUkJRUREA+/btq/F87969AQ75mUXk8BhW9f8XEBEhuP3CNddcw0033UTz5s1rPH/rrbeSmZnJoEGDSEhI4Oabb8bhcPDyyy+zY8eOsKngKSkpDBs2jH79+pGYmMjixYt55ZVXmDhxIs8++ywZGRkMHz6cyy67jK5du+JwOJg2bRqzZs3i/fff5+KLLz5oO5cvX84pp5yC2+3mhhtuoG3btmzZsoXPPvuMjIwMIBiuWrduTUpKCn/4wx8oLi7mxRdfJDk5maVLl4YFIcMwmDBhAs8991yt7zd//nxOOeUUYmNjadOmTVhggmC31JgxY5gxY0ZoXE0gEGDdunVMnTqVL7/8kv79+3Pbbbfx7bffcu6559K6dWtycnJ44YUXMAyDVatWER8ff6Q/MhGprmELRyJyLKrsljrYY9u2bZZlWdbSpUutkSNHWjExMZbX67XOOOMMa8GCBWHX+utf/2oNHDjQSkhIsDwej9W5c2fr0UcftcrKyizLsqw9e/ZYEyZMsDp37mxFR0db8fHx1qBBg6ypU6ceVltXrVplXXjhhVZCQoIVFRVlderUybrvvvvCzpk5c6bVvXt3y+VyWZ06dbL++9//HnQq+MG6pSwrOMU8PT3dAqy//vWvtZ5TVlZmPfbYY1a3bt0st9ttNWnSxOrXr5/10EMPhbrqZs+ebV1wwQVW8+bNLZfLZTVv3ty6/PLLrZ9++umwPrOIHJoqNyIiItKoaMyNiIiINCoKNyIiItKoKNyIiIhIo6JwIyIiIo2Kwo2IiIg0Kgo3IiIi0qg4GroB9c00TXbu3ElsbOyv2jlYRERE6o9lWRQUFNC8eXNstkPXZk64cLNz507S09MbuhkiIiJyFLZt20bLli0Pec4JF25iY2OB4M2p3PtGREREjm35+fmkp6eH/o4fygkXbiq7ouLi4hRuREREjjOHM6REA4pFRESkUVG4ERERkUZF4UZEREQalRNuzI2IiPx6gUCA8vLyhm6GNDIul+sXp3kfDoUbERE5bJZlkZ2dTW5ubkM3RRohm81G27Ztcblcv+o6CjciInLYKoNNs2bN8Hq9WgxVIqZykd2srCxatWr1q363FG5EROSwBAKBULBp2rRpQzdHGqHk5GR27tyJ3+/H6XQe9XU0oFhERA5L5Rgbr9fbwC2RxqqyOyoQCPyq6yjciIjIEVFXlNSVSP1uKdyIiIhIo6JwIyIicoTatGnDM88809DNkINQuBERkUbLMIxDPh588MGjuu6PP/7IDTfc8KvaNmzYMG677bZfdQ2pnWZLRYjPHyAn34fDbpAW72no5oiICJCVlRX6+t133+X+++9n/fr1oWMxMTGhry3LIhAI4HD88p/G5OTkyDZUIkqVmwhZtSOfU//xDeNe/r6hmyIiIhVSU1NDj/j4eAzDCH2/bt06YmNjmTFjBv369cPtdjNv3jw2btzIBRdcQEpKCjExMQwYMICvvvoq7LoHdksZhsFrr73GhRdeiNfrpUOHDnz88ce/qu0ffPAB3bp1w+1206ZNG5588smw51944QU6dOhAVFQUKSkpXHLJJaHn3n//fXr06IHH46Fp06aMGDGCoqKiX9We44kqNxFSOcDbwmrYhoiI1BPLsigp/3VTdo+Wx2mP2Mya//u//+OJJ56gXbt2NGnShG3btnHOOefw6KOP4na7efPNNxkzZgzr16+nVatWB73OQw89xD/+8Q8ef/xx/vWvf3HFFVewdetWEhMTj7hNS5Ys4bLLLuPBBx9k3LhxLFiwgJtvvpmmTZty9dVXs3jxYv7whz/w1ltvMWTIEPbt28d3330HBKtVl19+Of/4xz+48MILKSgo4LvvvsOyTpy/Two3EVL5n9gJ9LsjIie4kvIAXe//skHee83DI/G6IvMn7OGHH+ass84KfZ+YmEivXr1C3z/yyCNMmzaNjz/+mIkTJx70OldffTWXX345AH/729949tln+eGHHxg1atQRt+mpp55i+PDh3HfffQB07NiRNWvW8Pjjj3P11VeTmZlJdHQ05513HrGxsbRu3Zo+ffoAwXDj9/u56KKLaN26NQA9evQ44jYcz9QtFSGV/4JQuBEROb70798/7PvCwkLuvPNOunTpQkJCAjExMaxdu5bMzMxDXqdnz56hr6Ojo4mLiyMnJ+eo2rR27VqGDh0admzo0KH8/PPPBAIBzjrrLFq3bk27du248sorefvttykuLgagV69eDB8+nB49enDppZfy6quvsn///qNqx/FKlZsI0ZJWInKi8TjtrHl4ZIO9d6RER0eHfX/nnXcya9YsnnjiCdq3b4/H4+GSSy6hrKzskNc5cLsAwzAwTTNi7awuNjaWpUuXMmfOHGbOnMn999/Pgw8+yI8//khCQgKzZs1iwYIFzJw5k3/961/ce++9LFq0iLZt29ZJe441CjcREhpzo9KNiJwgDMOIWNfQsWT+/PlcffXVXHjhhUCwkrNly5Z6bUOXLl2YP39+jXZ17NgRuz0Y7BwOByNGjGDEiBE88MADJCQk8PXXX3PRRRdhGAZDhw5l6NCh3H///bRu3Zpp06Zx++231+vnaCiN77eygRgVtRtFGxGR41uHDh348MMPGTNmDIZhcN9999VZBWb37t1kZGSEHUtLS+OOO+5gwIABPPLII4wbN46FCxfy3HPP8cILLwDw6aefsmnTJk477TSaNGnC559/jmmadOrUiUWLFjF79mzOPvtsmjVrxqJFi9i9ezddunSpk89wLFK4iZCqyk3DtkNERH6dp556it///vcMGTKEpKQk/vSnP5Gfn18n7/XOO+/wzjvvhB175JFH+Mtf/sLUqVO5//77eeSRR0hLS+Phhx/m6quvBiAhIYEPP/yQBx98kNLSUjp06MD//vc/unXrxtq1a/n222955plnyM/Pp3Xr1jz55JOMHj26Tj7DsciwTrB+lPz8fOLj48nLyyMuLi5i1121I4/z/jWPlDg3i/48ImLXFRE5VpSWlrJ582batm1LVFRUQzdHGqFD/Y4dyd9vzZaKEFVuREREjg0KNxGiMTciIiLHBoWbCFHlRkRE5NigcBMhVauAK92IiIg0JIWbCAl1SynbiIiINKgGDTcvvvgiPXv2JC4ujri4OAYPHsyMGTMO+Zr33nuPzp07ExUVRY8ePfj888/rqbWHVrVxpoiIiDSkBg03LVu25O9//ztLlixh8eLFnHnmmVxwwQWsXr261vMXLFjA5ZdfzrXXXsuyZcsYO3YsY8eOZdWqVfXc8pqqNs5UvBEREWlIDRpuxowZwznnnEOHDh3o2LEjjz76KDExMXz//fe1nv/Pf/6TUaNGcdddd9GlSxceeeQR+vbty3PPPVfPLa9JlRsREZFjwzEz5iYQCDBlyhSKiooYPHhwrecsXLiQESPCF8gbOXIkCxcuPOh1fT4f+fn5YY+6oTE3IiIix4IGDzcrV64kJiYGt9vNjTfeyLRp0+jatWut52ZnZ5OSkhJ2LCUlhezs7INef9KkScTHx4ce6enpEW1/JW2cKSLSeA0bNozbbrst9H2bNm145plnDvkawzCYPn36r37vSF3nRNLg4aZTp05kZGSwaNEibrrpJsaPH8+aNWsidv177rmHvLy80GPbtm0Ru3Z1oTE3dXJ1ERE5GmPGjGHUqFG1Pvfdd99hGAYrVqw44uv++OOP3HDDDb+2eWEefPBBevfuXeN4VlZWne8LNXnyZBISEur0PepTg2+c6XK5aN++PQD9+vXjxx9/5J///Ccvv/xyjXNTU1PZtWtX2LFdu3aRmpp60Ou73W7cbndkG10LQ4NuRESOOddeey0XX3wx27dvp2XLlmHPvfHGG/Tv35+ePXse8XWTk5Mj1cRfdKi/cVK7Bq/cHMg0TXw+X63PDR48mNmzZ4cdmzVr1kHH6NQnVW5ERI495513HsnJyUyePDnseGFhIe+99x7XXnste/fu5fLLL6dFixZ4vV569OjB//73v0Ne98BuqZ9//pnTTjuNqKgounbtyqxZs2q85k9/+hMdO3bE6/XSrl077rvvPsrLy4Fg5eShhx5i+fLlGIaBYRihNh/YLbVy5UrOPPNMPB4PTZs25YYbbqCwsDD0/NVXX83YsWN54oknSEtLo2nTpkyYMCH0XkcjMzOTCy64gJiYGOLi4rjsssvCig3Lly/njDPOIDY2lri4OPr168fixYsB2Lp1K2PGjKFJkyZER0fTrVu3Ol/GpUErN/fccw+jR4+mVatWFBQU8M477zBnzhy+/PJLAK666ipatGjBpEmTALj11ls5/fTTefLJJzn33HOZMmUKixcv5pVXXmnIjwFozI2InIAsC8qLG+a9nd7qS8MflMPh4KqrrmLy5Mnce++9oSr7e++9RyAQ4PLLL6ewsJB+/frxpz/9ibi4OD777DOuvPJKTjrpJAYOHPiL72GaJhdddBEpKSksWrSIvLy8sPE5lWJjY5k8eTLNmzdn5cqVXH/99cTGxnL33Xczbtw4Vq1axRdffMFXX30FQHx8fI1rFBUVMXLkSAYPHsyPP/5ITk4O1113HRMnTgwLcN988w1paWl88803bNiwgXHjxtG7d2+uv/76X/w8tX2+ymAzd+5c/H4/EyZMYNy4ccyZMweAK664gj59+vDiiy9it9vJyMjA6XQCMGHCBMrKyvj222+Jjo5mzZo1xMTEHHE7jkSDhpucnByuuuoqsrKyiI+Pp2fPnnz55ZecddZZQDAp2mxVxaUhQ4bwzjvv8Je//IU///nPdOjQgenTp9O9e/eG+ggh2jhTRE445cXwt+YN895/3gmu6MM69fe//z2PP/44c+fOZdiwYUCwS+riiy8OTTa58847Q+ffcsstfPnll0ydOvWwws1XX33FunXr+PLLL2nePHg//va3v9UYJ/OXv/wl9HWbNm248847mTJlCnfffTcej4eYmBgcDschu6HeeecdSktLefPNN4mODn7+5557jjFjxvDYY4+FJt00adKE5557DrvdTufOnTn33HOZPXv2UYWb2bNns3LlSjZv3hyalPPmm2/SrVs3fvzxRwYMGEBmZiZ33XUXnTt3BqBDhw6h12dmZnLxxRfTo0cPANq1a3fEbThSDRpu/v3vfx/y+cpEWN2ll17KpZdeWkctOnraOFNE5NjUuXNnhgwZwuuvv86wYcPYsGED3333HQ8//DAQXIrkb3/7G1OnTmXHjh2UlZXh8/nwer2Hdf21a9eSnp4eCjZArcMl3n33XZ599lk2btxIYWEhfr+fuLi4I/osa9eupVevXqFgAzB06FBM02T9+vWhcNOtWzfsdnvonLS0NFauXHlE71X9PdPT08NmG3ft2pWEhATWrl3LgAEDuP3227nuuut46623GDFiBJdeeiknnXQSAH/4wx+46aabmDlzJiNGjODiiy8+qnFOR6LBBxQ3NqbSjYicKJzeYAWlod77CFx77bXccsstPP/887zxxhucdNJJnH766QA8/vjj/POf/+SZZ56hR48eREdHc9ttt1FWVhax5i5cuJArrriChx56iJEjRxIfH8+UKVN48sknI/Ye1VV2CVUyDAPTNOvkvSA40+u3v/0tn332GTNmzOCBBx5gypQpXHjhhVx33XWMHDmSzz77jJkzZzJp0iSefPJJbrnlljprzzE3oPh4pclSInLCMYxg11BDPA5jvE11l112GTabjXfeeYc333yT3//+96HxN/Pnz+eCCy7gd7/7Hb169aJdu3b89NNPh33tLl26sG3bNrKyskLHDlxpf8GCBbRu3Zp7772X/v3706FDB7Zu3Rp2jsvlIhAI/OJ7LV++nKKiotCx+fPnY7PZ6NSp02G3+UhUfr7qS6msWbOG3NzcsHXpOnbsyB//+EdmzpzJRRddxBtvvBF6Lj09nRtvvJEPP/yQO+64g1dffbVO2lpJ4SZCNBVcROTYFRMTw7hx47jnnnvIysri6quvDj3XoUMHZs2axYIFC1i7di3/7//9vxrLjhzKiBEj6NixI+PHj2f58uV899133HvvvWHndOjQgczMTKZMmcLGjRt59tlnmTZtWtg5bdq0YfPmzWRkZLBnz55aZw5fccUVREVFMX78eFatWsU333zDLbfcwpVXXlljkdsjFQgEyMjICHusXbuWESNG0KNHD6644gqWLl3KDz/8wFVXXcXpp59O//79KSkpYeLEicyZM4etW7cyf/58fvzxR7p06QLAbbfdxpdffsnmzZtZunQp33zzTei5uqJwEyG2ULZRuhERORZde+217N+/n5EjR4aNj/nLX/5C3759GTlyJMOGDSM1NZWxY8ce9nVtNhvTpk2jpKSEgQMHct111/Hoo4+GnXP++efzxz/+kYkTJ9K7d28WLFjAfffdF3bOxRdfzKhRozjjjDNITk6udTq61+vlyy+/ZN++fQwYMIBLLrmE4cOHR2SPxcLCQvr06RP2GDNmDIZh8NFHH9GkSRNOO+00RowYQbt27Xj33XcBsNvt7N27l6uuuoqOHTty2WWXMXr0aB566CEgGJomTJhAly5dGDVqFB07duSFF1741e09FMM6weYu5+fnEx8fT15e3hEP5DqU7LxSTp40G4fNYMPfzonYdUVEjhWlpaVs3ryZtm3bEhUV1dDNkUboUL9jR/L3W5WbCFGvlIiIyLFB4SZCQisUn1iFMBERkWOOwk2kqHIjIiJyTFC4iZDQCsVKNyIiIg1K4SZCjnDJBREREakjCjcRUj3baNyNiIhIw1G4iRCjWulG2UZERKThKNxESFjlpsFaISIiIgo3EVJ9zI26pURERBqOwk2EGNVqN4o2IiIiDUfhJlLCKjcN1wwREaliGMYhHw8++OCvuvb06dMjdp5EjqOhG9BYhHVLqXYjInJMyMrKCn397rvvcv/997N+/frQsZiYmIZoltQxVW4iJHwqeIM1Q0REqklNTQ094uPjMQwj7NiUKVPo0qULUVFRdO7cOWy36rKyMiZOnEhaWhpRUVG0bt2aSZMmAdCmTRsALrzwQgzDCH1/pEzT5OGHH6Zly5a43W569+7NF198cVhtsCyLBx98kFatWuF2u2nevDl/+MMfju5GNTKq3ESIoVX8ROQEY1kWJf6SBnlvj8Pzq/9/9+233+b+++/nueeeo0+fPixbtozrr7+e6Ohoxo8fz7PPPsvHH3/M1KlTadWqFdu2bWPbtm0A/PjjjzRr1ow33niDUaNGYbfbj6oN//znP3nyySd5+eWX6dOnD6+//jrnn38+q1evpkOHDodswwcffMDTTz/NlClT6NatG9nZ2SxfvvxX3ZPGQuEmQlS5EZETTYm/hEHvDGqQ917020V4nd5fdY0HHniAJ598kosuugiAtm3bsmbNGl5++WXGjx9PZmYmHTp04JRTTsEwDFq3bh16bXJyMgAJCQmkpqYedRueeOIJ/vSnP/Gb3/wGgMcee4xvvvmGZ555hueff/6QbcjMzCQ1NZURI0bgdDpp1aoVAwcOPOq2NCbqlooQjbkRETl+FBUVsXHjRq699lpiYmJCj7/+9a9s3LgRgKuvvpqMjAw6derEH/7wB2bOnBnRNuTn57Nz506GDh0adnzo0KGsXbv2F9tw6aWXUlJSQrt27bj++uuZNm0afr8/om08XqlyEyFhU8GVbUTkBOBxeFj020UN9t6/RmFhIQCvvvoqgwaFV58qu5j69u3L5s2bmTFjBl999RWXXXYZI0aM4P333/9V730kDtWG9PR01q9fz1dffcWsWbO4+eabefzxx5k7dy5Op7Pe2ngsUriJkPDKjYhI42cYxq/uGmooKSkpNG/enE2bNnHFFVcc9Ly4uDjGjRvHuHHjuOSSSxg1ahT79u0jMTERp9NJIBA46jbExcXRvHlz5s+fz+mnnx46Pn/+/LDupUO1wePxMGbMGMaMGcOECRPo3LkzK1eupG/fvkfdrsZA4aYOaIViEZFj30MPPcQf/vAH4uPjGTVqFD6fj8WLF7N//35uv/12nnrqKdLS0ujTpw82m4333nuP1NRUEhISgOCMqdmzZzN06FDcbjdNmjQ56Htt3ryZjIyMsGMdOnTgrrvu4oEHHuCkk06id+/evPHGG2RkZPD2228DHLINkydPJhAIMGjQILxeL//973/xeDxh43JOVAo3EaLKjYjI8eW6667D6/Xy+OOPc9dddxEdHU2PHj247bbbAIiNjeUf//gHP//8M3a7nQEDBvD5559jswWHqz755JPcfvvtvPrqq7Ro0YItW7Yc9L1uv/32Gse+++47/vCHP5CXl8cdd9xBTk4OXbt25eOPP6ZDhw6/2IaEhAT+/ve/c/vttxMIBOjRoweffPIJTZs2jfi9Ot4Y1glWZsjPzyc+Pp68vDzi4uIidt0yv0nHv8wAYPkDZxPvObH7O0Wk8SktLWXz5s20bduWqKiohm6ONEKH+h07kr/fmi0VIYa2BRcRETkmKNxESHi2UboRERFpKAo3EVJ9pUxT2UZERKTBKNxESPgKxUo3IiIiDUXhJkI0W0pEThT6B5zUlUj9bincREj1bin9dy8ijVHlqrfFxcUN3BJprMrKygCOeiPSSlrnpg5oQLGINEZ2u52EhARycnIA8Hq9v3pnbpFKpmmye/duvF4vDseviycKNxFkGBVVG2UbEWmkKnfArgw4IpFks9lo1arVrw7NCjcRZBDMNco2ItJYGYZBWloazZo1o7y8vKGbI42My+UKrQD9ayjcRJBRUbrRmBsRaezsdvuvHhchUlc0oDiCbBVVNI25ERERaTgKNxFkVKx2o8qNiIhIw1G4iaRQ5UZEREQaisJNBFWO7dYCVyIiIg1H4SaCKmeuKduIiIg0HIWbCDLQYlYiIiINrUHDzaRJkxgwYACxsbE0a9aMsWPHsn79+kO+ZvLkyRiGEfaIioqqpxYfmio3IiIiDa9Bw83cuXOZMGEC33//PbNmzaK8vJyzzz6boqKiQ74uLi6OrKys0GPr1q311OJDC4250ZBiERGRBtOgi/h98cUXYd9PnjyZZs2asWTJEk477bSDvs4wjNAS4MeSyuWiVbkRERFpOMfUmJu8vDwAEhMTD3leYWEhrVu3Jj09nQsuuIDVq1cf9Fyfz0d+fn7Yo65UVW5ERESkoRwz4cY0TW677TaGDh1K9+7dD3pep06deP311/noo4/473//i2maDBkyhO3bt9d6/qRJk4iPjw890tPT6+ojVK1zo9KNiIhIgzGsY+Qv8U033cSMGTOYN28eLVu2POzXlZeX06VLFy6//HIeeeSRGs/7fD58Pl/o+/z8fNLT08nLyyMuLi4iba/U88EvyS/1M/uO0zkpOSai1xYRETmR5efnEx8ff1h/v4+JjTMnTpzIp59+yrfffntEwQbA6XTSp08fNmzYUOvzbrcbt9sdiWb+Io25ERERaXgN2i1lWRYTJ05k2rRpfP3117Rt2/aIrxEIBFi5ciVpaWl10MIjY4SWuVG6ERERaSgNWrmZMGEC77zzDh999BGxsbFkZ2cDEB8fj8fjAeCqq66iRYsWTJo0CYCHH36Yk08+mfbt25Obm8vjjz/O1q1bue666xrsc1Sq2n6hQZshIiJyQmvQys2LL75IXl4ew4YNIy0tLfR49913Q+dkZmaSlZUV+n7//v1cf/31dOnShXPOOYf8/HwWLFhA165dG+IjhKnslnLu+wnevgx2LG3gFomIiJx4jpkBxfXlSAYkHal+j8xib1EZPze9HWdRNjii4C+7IvoeIiIiJ6Ij+ft9zEwFbwwqx9w4i4Lda/hLG64xIiIiJyiFm4jSxpkiIiINTeEmggxlGxERkQancBNByjYiIiINT+EmgmpUbhxRDdIOERGRE5nCTQQZB9ZuHPWzMrKIiIhUUbiJoBqVG6e3QdohIiJyIlO4iaAaY27ULSUiIlLvFG4iyDiwdKNwIyIiUu8UbiLMhln1jVPhRkREpL4p3ESQYYCXaqsSOzwN1xgREZETlMJNBAXDja/qgM3ecI0RERE5QSncRJCBQYxRUnXAMg9+soiIiNQJhZsIqtEtZQYarjEiIiInKIWbCDKA6OrdUqa/wdoiIiJyolK4iSDDMIgO65ZS5UZERKS+KdxEkGFAdFi3lCo3IiIi9U3hJoIMwGtU75bSgGIREZH6pnATQYZh4KK86oAqNyIiIvVO4SaCDMDAqjqgMTciIiL1TuEmggwDbNXDjaaCi4iI1DuFmwgyMBRuREREGpjCTQQZBhjVN85Ut5SIiEi9U7iJsPDKjQYUi4iI1DeFmwgyDCN8QLG6pUREROqdwk0EGahyIyIi0tAUbiKoxmwp7QouIiJS7xRuIig4oFiVGxERkYakcBNBwang1ao1GnMjIiJS7xRuIihYualGlRsREZF6p3ATQQZgMw5Y58ayDnq+iIiIRJ7CTSQdOBUcNKhYRESknincRFDlVHAT+MnpJAAadyMiIlLPFG4iKDgV3OSlhHgubpnGPxKbaNyNiIhIPVO4iSCj4vFik3gA3omP1f5SIiIi9UzhJoIM44BdwUHdUiIiIvVM4SaCgpWbAwYQK9yIiIjUK4WbCKqx/QKoW0pERKSeKdxEUHCF4gO7pTSgWEREpD4p3ERSxWypMOqWEhERqVcKNxFk1HZQlRsREZF6pXATQUZtlRutUCwiIlKvFG4i6MAxN4ZlqXIjIiJSzxo03EyaNIkBAwYQGxtLs2bNGDt2LOvXr//F17333nt07tyZqKgoevToweeff14Prf1lB86WcoDG3IiIiNSzBg03c+fOZcKECXz//ffMmjWL8vJyzj77bIqKig76mgULFnD55Zdz7bXXsmzZMsaOHcvYsWNZtWpVPba8doYRvs6NQ5UbERGRemdYlmX98mn1Y/fu3TRr1oy5c+dy2mmn1XrOuHHjKCoq4tNPPw0dO/nkk+nduzcvvfTSL75Hfn4+8fHx5OXlERcXF7G2A/zutUWcu2USf+uwEYDYgMmCUf+F5n0i+j4iIiInmiP5+31MjbnJy8sDIDEx8aDnLFy4kBEjRoQdGzlyJAsXLqz1fJ/PR35+ftijrhzYLWXHUreUiIhIPTtmwo1pmtx2220MHTqU7t27H/S87OxsUlJSwo6lpKSQnZ1d6/mTJk0iPj4+9EhPT49ouw9kC+uWQuFGRESknh0z4WbChAmsWrWKKVOmRPS699xzD3l5eaHHtm3bInr96myGgWVUCzdY2n5BRESknjkaugEAEydO5NNPP+Xbb7+lZcuWhzw3NTWVXbt2hR3btWsXqamptZ7vdrtxu90Ra+uhGAYEDA0oFhERaUgNWrmxLIuJEycybdo0vv76a9q2bfuLrxk8eDCzZ88OOzZr1iwGDx5cV808bAbgt1WFGzuoW0pERKSeNWjlZsKECbzzzjt89NFHxMbGhsbNxMfH4/F4ALjqqqto0aIFkyZNAuDWW2/l9NNP58knn+Tcc89lypQpLF68mFdeeaXBPkclwzAwq1VuTFC4ERERqWcNWrl58cUXycvLY9iwYaSlpYUe7777buiczMxMsrKyQt8PGTKEd955h1deeYVevXrx/vvvM3369EMOQq4vBuHdUn7D0JgbERGRetaglZvDWWJnzpw5NY5deumlXHrppXXQol/HMMBfLdwEQGNuRERE6tkxM1uqcTAI2A6o3KhbSkREpF4p3ERQsHJTVY1S5UZERKT+KdxE0IFjbgKGAZZ58BeIiIhIxCncRJAqNyIiIg1P4SaCDIywAcXlGnMjIiJS7xRuIsgwCBtQrMqNiIhI/VO4iSDDgEC1XcEtw8BUuBEREalXCjcRZGAERxVXEzDLG6YxIiIiJyiFm0gywCJ8YUJ/QOFGRESkPincRFCwaBMebgLqlhIREalXCjcRZBgGGAdUbsyyBmqNiIjIiUnhJoKMWo75A6rciIiI1CeFmwgyDLAMdUuJiIg0JIWbCKp1zI2lcCMiIlKfFG4iyDBqdkypciMiIlK/FG4iyKCWqeCWtl8QERGpTwo3kWRQY1SxX5UbERGReqVwE0EGBhZm2LGAKjciIiL1SuEmgmoZcqMxNyIiIvVM4SaCapst5TfN2k4VERGROqJwE0FGLWNu1C0lIiJSvxRuIig45iac1rkRERGpXwo3EWTUsit4uaVuKRERkfqkcBNB2n5BRESk4SncRFQtKxSrciMiIlKvjircbNu2je3bt4e+/+GHH7jtttt45ZVXItaw41Ft3VIaUCwiIlK/jirc/Pa3v+Wbb74BIDs7m7POOosffviBe++9l4cffjiiDTye1DYVvMxUuBEREalPRxVuVq1axcCBAwGYOnUq3bt3Z8GCBbz99ttMnjw5ku07rtgMA+uAlfwKfGUN1BoREZET01GFm/LyctxuNwBfffUV559/PgCdO3cmKysrcq07ztTWLZWvcCMiIlKvjircdOvWjZdeeonvvvuOWbNmMWrUKAB27txJ06ZNI9rA44lBzdlSZQF1S4mIiNSnowo3jz32GC+//DLDhg3j8ssvp1evXgB8/PHHoe6qE5Fh1FzEz0SzpUREROqT42heNGzYMPbs2UN+fj5NmjQJHb/hhhvwer0Ra1xjoKngIiIi9euoKjclJSX4fL5QsNm6dSvPPPMM69evp1mzZhFt4PGk1qngqtyIiIjUq6MKNxdccAFvvvkmALm5uQwaNIgnn3ySsWPH8uKLL0a0gccTAwOrxsaZCjciIiL16ajCzdKlSzn11FMBeP/990lJSWHr1q28+eabPPvssxFt4PEkWLkJp8qNiIhI/TqqcFNcXExsbCwAM2fO5KKLLsJms3HyySezdevWiDbweFLbIn6q3IiIiNSvowo37du3Z/r06Wzbto0vv/ySs88+G4CcnBzi4uIi2sDjSW2VG7PGEREREalLRxVu7r//fu68807atGnDwIEDGTx4MBCs4vTp0yeiDTyeGEbNMTeaCi4iIlK/jmoq+CWXXMIpp5xCVlZWaI0bgOHDh3PhhRdGrHHHG4NaKjeWKjciIiL16ajCDUBqaiqpqamh3cFbtmx5Qi/gB0C1qeCGZWAZlrqlRERE6tlRdUuZpsnDDz9MfHw8rVu3pnXr1iQkJPDII49gmiduN4xB1QrFNqtyeLHCjYiISH06qsrNvffey7///W/+/ve/M3ToUADmzZvHgw8+SGlpKY8++mhEG3m8MAxCY26Mii805kZERKR+HVXl5j//+Q+vvfYaN910Ez179qRnz57cfPPNvPrqq0yePPmwr/Ptt98yZswYmjdvjmEYTJ8+/ZDnz5kzB8Mwajyys7OP5mNEXPUxNwaq3IiIiDSEowo3+/bto3PnzjWOd+7cmX379h32dYqKiujVqxfPP//8Eb3/+vXrycrKCj2OlS0fDINQncZmBW+t6jYiIiL166i6pXr16sVzzz1XYzXi5557jp49ex72dUaPHs3o0aOP+P2bNWtGQkLCEb+urlUfc4O6pURERBrEUYWbf/zjH5x77rl89dVXoTVuFi5cyLZt2/j8888j2sDa9O7dG5/PR/fu3XnwwQdD435q4/P58Pl8oe/z8/PrrF3BMTeVs6VUuREREWkIR9Utdfrpp/PTTz9x4YUXkpubS25uLhdddBGrV6/mrbfeinQbQ9LS0njppZf44IMP+OCDD0hPT2fYsGEsXbr0oK+ZNGkS8fHxoUd6enqdtc8I+zp4azXmRkREpH4ZlhW5VeaWL19O3759CQQCR94Qw2DatGmMHTv2iF53+umn06pVq4OGqtoqN+np6eTl5UV8q4inZq5n3aZzWejx4PXFUuwuYHiBxTMTV0X0fURERE40+fn5xMfHH9bf76NexO9YMXDgQObNm3fQ591uN263u17aYmBhVtZvLFVuREREGsJRdUsdSzIyMkhLS2voZgBgM6rWI64cc1M5BkdERETqR4NWbgoLC9mwYUPo+82bN5ORkUFiYiKtWrXinnvuYceOHbz55psAPPPMM7Rt25Zu3bpRWlrKa6+9xtdff83MmTMb6iOEsVnVBxBrQLGIiEhDOKJwc9FFFx3y+dzc3CN688WLF3PGGWeEvr/99tsBGD9+PJMnTyYrK4vMzMzQ82VlZdxxxx3s2LEDr9dLz549+eqrr8Ku0ZCqV27ULSUiItIwjijcxMfH/+LzV1111WFfb9iwYRxqPPOBqx3ffffd3H333Yd9/fpmWFZo+wUsOxCs3FiWhWEYB32diIiIRM4RhZs33nijrtrRKNiMqgHFVrUxN37TwmlXuBEREakPx/2A4mOJDavaGJuqyk15QCNvRERE6ovCTQQZVI25sSq7pQwoD2jcjYiISH1RuIkgGxbmAWNuLCxVbkREROqRwk0EGVBtzE1Vt5RflRsREZF6o3ATQbbq3VIVY24sQ2NuRERE6pPCTQQFZ0sFVa/clCnciIiI1BuFmwiyWVVjbqzQmBt1S4mIiNQnhZsICl+huPpsKVVuRERE6ovCTSRZtQ8oVreUiIhI/VG4iSCbYdWyzo2lbikREZF6pHATQYZlVo25Ca1QbFDuDzRgq0RERE4sCjcRVNtsqYABfn95wzVKRETkBKNwE0E2y8SqZcyNKjciIiL1R+EmggyD0Jgb0wpuuG5i4A/4G65RIiIiJxiFmwgyMGusc2Ma4Pcr3IiIiNQXhZsIslnVxtwQrNwEAL+6pUREROqNwk0EGdWmgptW1Wwpf0ADikVEROqLwk0EGZZZbRG/isqNAQFVbkREROqNwk0E2bCwKsbcmNVmS/kDCjciIiL1ReEmggygaqOFynVuDAIaUCwiIlJvFG4iyIZZFW6s4K01gYCmgouIiNQbhZsIMqi5iF8Ag3J1S4mIiNQbhZsIsmGF1rmhItxYBpjqlhIREak3CjcRZFRb56ayWyqAuqVERETqk8JNJFVb5waqZksFAuZBXiAiIiKRpnATQbZq69zYqs+WUuVGRESk3ijcRJBRbcyNEVa50YBiERGR+qJwE0E2qrqlbBV7S5mGgantF0REROqNwk0EGdXWubHZ7KHj5aa6pUREROqLwk0EGVhYRrBfyk5VuNHGmSIiIvVH4SaSrOqzoqrCjbqlRERE6o/CTQQZ1XeWMqrCjQYUi4iI1B+FmwiyrKoQYzccoa8Dpio3IiIi9UXhJqKqKje26pUbDSgWERGpNwo3EVUt3FC9cqNwIyIiUl8UbiKpereUrfqAYo25ERERqS8KNxFkWVU7S9kMA3vFtwFLY25ERETqi8JNBBlhY25soZtrqVtKRESk3ijcRJBhVJ8tZQ/d3ICpbikREZH6onATQXajWuXGVlW5MS1VbkREROqLwk0Eue3VF/GzYSO4FYMZtnKxiIiI1KUGDTfffvstY8aMoXnz5hiGwfTp03/xNXPmzKFv37643W7at2/P5MmT67ydh6t6uLEZRmgDBlNjbkREROpNg4aboqIievXqxfPPP39Y52/evJlzzz2XM844g4yMDG677Tauu+46vvzyyzpu6eFx2YLTowwL7DajWuVGY25ERETqi+OXT6k7o0ePZvTo0Yd9/ksvvUTbtm158sknAejSpQvz5s3j6aefZuTIkXXVzMPmsgVDjAEETCtUubGqjbnZU+jj0pcWcmGfFvxheIf6b6SIiEgjd1yNuVm4cCEjRowIOzZy5EgWLlx40Nf4fD7y8/PDHnXFaQt2SxlAcVkgVLnBMjHNYFXnh8372LyniM9WZNVZO0RERE5kx1W4yc7OJiUlJexYSkoK+fn5lJSU1PqaSZMmER8fH3qkp6fXWfuMiu4nw4LiMj/Vdpei3AwGn90FPgBK/eqqEhERqQvHVbg5Gvfccw95eXmhx7Zt2+rsvSoHDhsYFPkC2Ixg5cZmmJQHgpWbnIJSAErLFW5ERETqQoOOuTlSqamp7Nq1K+zYrl27iIuLw+Px1Poat9uN2+2uj+ZhmlXbLJSUB7BXdksZJuV+E9xVlZuSMoUbERGRunBcVW4GDx7M7Nmzw47NmjWLwYMHN1CLwlVus2BU7ClVOebGZpihbqmcym6pcq19IyIiUhcaNNwUFhaSkZFBRkYGEJzqnZGRQWZmJhDsUrrqqqtC5994441s2rSJu+++m3Xr1vHCCy8wdepU/vjHPzZE82swA1XdUkCoW8ogEOqWqqzclAVMAqZVy1VERETk12jQcLN48WL69OlDnz59ALj99tvp06cP999/PwBZWVmhoAPQtm1bPvvsM2bNmkWvXr148sknee21146JaeBQc7G+ym4pAxN/ILxyAxp3IyIiUhcadMzNsGHDsKyDVy9qW3142LBhLFu2rA5bdfQs84DKTWW4MUzKKyo1ewvDw020+7ga9iQiInLMO67G3BzrzAPG3NgrZ0sRoMxvsbfIR/WeqBJVbkRERCJO4SaCqrZZqAw1wdtrGCZ+0wyNt6mkbikREZHIU59IBFkVU8Eru6XsRtWYm/KAyd6i8DE5mjElIiISearcRJBpVu4tZfD4JT3DxtyU+a0alRt1S4mIiESewk0EVQ4ojnU7ubR/OjajoluKgLqlRERE6onCTQRVjrmpXN+mslsKw6TMXzPcaJViERGRyFO4iaDQbCkjfECxrWLMTeW+UpXULSUiIhJ5CjcRZFWMuQmFmspuKcPCV0vlxqcBxSIiIhGncBNBNSo3RuXtDXZLVa5OnBwb3MhTlRsREZHIU7iJoKrKTTDcOEKVm+DeUpWVm1aJXkADikVEROqCwk0EVQ4oNozwbimw2F9cRnHFAOLKcKPKjYiISOQp3ERQqHJjhFduMEz2FpYFj9kMEqNdgMKNiIhIXVC4iSDTqtw4M3hb7dgrnyGvJLh6cZTTjscZPK4BxSIiIpGncBNBZqhyUxFubFWVm/zSqnAT5Qwer77Ozd9/+DsXfnQhhWWF9dhiERGRxkfhJoKsGov4VVRuDJOCULixEVVRuSn1B8/P8+Xx9tq32ZC7gQU7F9Rzq0VERBoXhZsIOnBAsaMi3FiGRX5JsMsqymnH4woer6zczN8xP3QNvxm+uaaIiIgcGYWbCLIO6Jaqvs5NfrXKTeWYm8oBxXO3zw1dY79vfz21VkREpHFSuIkg0woOEK4ac1NZuTEpKK2o3DjseCsqN5VTw7cVbAtdY1/pvnprr4iISGOkcBNBoW4pwrulgLABxR6XA6gKN0XlRaHz9peqciMiIvJrKNxEUGW3VOWYG7tRVbmxrOA5Uc6qyk1JWbCao3AjIiISOQo3EVRW0S3lsjkBsNuCFRoLK3ROlNNWo1uq2F8cel7dUiIiIr+Owk0ElVZ0S7ntwRWIHbaqqeCVgpWbYOgpKQtgWRbF5VXhZn/JnnpqrYiISOOkcBNBPoIhJsoeBYCtolvKPEjlpqjMT6m/lIBVtZjf/uLd9dVcERGRRknhJoJ8Fd1SbocbALtR0S1lVAs3jqp1bkwLckvDVyTOC5QQMLXnlIiIyNFSuImg0gMqNw5b1SJ+laKcdrzOqllU+4oLAHBWjDi2gFxfbj20VkREpHFSuIkgX0X3U6hyUzGwuPqAYo/LjsNuw+UI3vp9pcFwExcwiTGD4Si/LL/e2iwiItLYKNxEUGko3AQrN/ZaKjfuilBTOe5mf0mwWyraMvFWhJsSf0n9NFhERKQRUriJoMrKTZTdA4CjYip4+IDiYKip7JqqHHPjNS08FV1TBb6q2VMiIiJyZBRuIsU0KQ1uBo7bEQw3ttCA4qrTQuHGHXwuz1cRbiwTrxkMN28sXFcfLRYREWmUFG4ixQrgM4IpJqoi3NhrrdyEd0sV+IJjbqJNC0/FbKuv128P7RguIiIiR0bhJlIC5ZTagrfT7azslqoYUHzAVHAgtDN4UWkeAF7TxFNRuTGMEvYU+uqn3SIiIo2Mwk2kmH5KQ5UbL1B75aZyjZvQFgwV076jLQtvxZibaFsBe4vK6qXZIiIijY3CTaSY/qpuKWdFuLEHKzdm2Jibim6pijE3pWXByo3TtOGwgoHHbStkryo3IiIiR0XhJlLMqjE3oW6pigHF1cON2xE+W6q0PDjmxmHacVWEG4ethL2FqtyIiIgcDUdDN6DRCOuWqhhQbD/EVPCKbimfvyh4runARfCY3VbKniJVbkRERI6GKjeRYpZXVW7swRWKbRUDigO1dEt5KnYGLwsE17QxTCcugruJ222l7KtWuTFNi427C7GsqpAkIiIitVO4iRTTT6ktPNyEZktVOy3BGwww0RWVG79ZGjzHdOIygs8ZtrLQgOLS8gDj3/iB4U/O5bOVWXX+MURERI53CjeRYlZf56Zy+4Xwyk0Tr5OYioHECdHBIFNuBkOMablw24KvM2xloang7yzK5Luf9wCwYOPeevggIiIixzeFm0ipNluqsnJz4JibgW0TQ6cnx1SEGysYbgKWOzRWxzLKQwOKt+wtCr0mc6+2ZRAREfklCjcR4vf78FdWbuzBCozDHgwwlZWbc3qkhc5PigkGIL9VHvxf043bEQ2AafOzu6JyU+jzh16zaXdhHX4CERGRxkHhJkJ8/qqqittRUbmxVa5zY/CnUZ05v1fz0DmhcEMwvPjNKLzOauGmwMeqHXkUVQs3O/NKw74XERGRmhRuIqS0vCT0dY3ZUsBNw07CMKqmTSXFBs8JGMH9pMrMKJJimwSfdASPvfvjNop84XtMbd5TxIHK/GZkPoSIiEgjoHATIT5nMKy4sWEzgrc1rFvqgGnc0S47Hqcdvy0YTOzOGFLjg2NyKo99+/PusG4pgCdmrsfnrwo8yzL30/3BL3lhzobIfygREZHj0DERbp5//nnatGlDVFQUgwYN4ocffjjouZMnT8YwjLBHVFRUPba2dqXxwS4ntysmdKxyb6kAgBlegTEMg6RYF/6Kyk1qQiLRUcHKTSnBY1l5paFwM/GM9kQ5bcxZv5vXvtscus4d7y2nzG/yjy/W18nnEhEROd40eLh59913uf3223nggQdYunQpvXr1YuTIkeTk5Bz0NXFxcWRlZYUeW7durccW187nDw4ArhxMDGCv6J4KYIAVqPGapjEuyit6qtokJeOJSghey7AAkzK/ybZ9wbE8Z3VN4W8X9gDg+W82kFccHIi8O18rGYuIiFTX4OHmqaee4vrrr+eaa66ha9euvPTSS3i9Xl5//fWDvsYwDFJTU0OPlJSUemxx7XyBYMioHEwM4LBXW+fGrDkQeH9RCVZFuOndpjneisoNQNPYiutWjKeJdjsY27sFrRK9FJcFWL49F4ACDTAWEREJ06DhpqysjCVLljBixIjQMZvNxogRI1i4cOFBX1dYWEjr1q1JT0/nggsuYPXq1Qc91+fzkZ+fH/aoC+mx6Uw6dRJ/7PfH0DG7rWLMDUaNbimAxJiq298sPhF3VBOMirE5yfFG2LmxUQ5sNoNuzeMAWJ9dgD8QPpDYNLU9g4iISIOGmz179hAIBGpUXlJSUsjOzq71NZ06deL111/no48+4r///S+maTJkyBC2b99e6/mTJk0iPj4+9EhPT4/45wBo6mnKee3O46zWZ4WO2SoGFPsPUrm5+5x2ABiWhcsZixEVi7ci3CTFhoeb6IqVjTulBks667ILyNwXvqhfXkl5ZD6MiIjIcazBu6WO1ODBg7nqqqvo3bs3p59+Oh9++CHJycm8/PLLtZ5/zz33kJeXF3ps27at3toami2FAVbN6dqtmgafd1sWhssLrmg8FdWXJjHhVRhvxW7inSvCzU+7Cli8dX/YOZX7UYmIiJzIHA355klJSdjtdnbt2hV2fNeuXaSmph7WNZxOJ3369GHDhtqnQrvdbtxud63P1bXQ9gsGtXZLVQ5CdlsWOD3gisVrmYCdeG+Ayh9PtMuOrWJTzk6pwW6pn3YV8N/vwwdS7y300b5ZDCIiIieyBq3cuFwu+vXrx+zZs0PHTNNk9uzZDB48+LCuEQgEWLlyJWlpab98cj2zGxU7fxsGVqBml1FpILgjeFW4icZbWblxl4bOq+ySAmiV6CUuyoHPb7Jiex5Ou0G7pODKxkdSuTFNi+IyDUYWEZHGp8G7pW6//XZeffVV/vOf/7B27VpuuukmioqKuOaaawC46qqruOeee0LnP/zww8ycOZNNmzaxdOlSfve737F161auu+66hvoIB+WwVYUS06oZbnz+YICJsixweMDpwVMx5qappyrcxFQLN3abwYguVWOURnVPo0NKsFrz5Mz19H1kFmt2/vKg6Vv+t4z+f/2K7LzSXzxXRETkeNLg4WbcuHE88cQT3H///fTu3ZuMjAy++OKL0CDjzMxMsrKyQufv37+f66+/ni5dunDOOeeQn5/PggUL6Nq1a0N9hIOqrNwABPw1qyqlZQUAuCorN4aBt+JHEletcpN7wEDhUd2ruuyuPLk1TSv2qdq4u4h9RWXc8d7yQ7bLNC0+W5lFcVmAT1fsPMJPJSIicmxr0DE3lSZOnMjEiRNrfW7OnDlh3z/99NM8/fTT9dCqX69yGwYAf6Ac1wHP+3zBCktUZbgBPBWBqKy8qvqy74DuptM6JjOwbSJNo10MaNOEeRv2hD2/dW9w/6lCn58r/72Ibs3j+OvYHqHnt++v2gfLbguflSUiInK8OybCTWNVvVsqEKi5knBpWSEAbguoWPDPa3MAJiW+goNeN8ppZ+r/qxqT1DUtLuz54rIAhT4/H2XsYFlmLssyc/nLuV2JqphxtX5X1bV3F2iFYxERaVwavFuqMaveLWXWss6NryLcRFX7MXgqFv4rLivgrpGdALigd/NDvk/fVgk1jo351zw+yqjqclqfXRVofqoWbjTmRkREGhtVbupQeLdUzTE3vvKKyk2187w2F1BKcXkht595En1aJdA7PeGQ79MsLnzj0GiXnc17iti8pyh0bPXOfHpVXGddtaCTna9wIyIijYsqN3XIMAwcFbOfAmZtA4qDKwy7q1V4PI5gUCkpL8ZuMxhyUhJe1y9n0KSYYMXnjE7JfH3nsBrVnIxt+5m6eBs/7yrgqzVV6wodbuXmpbkbmfpj/S2AKCIicrRUualjdgz8QKC2bil/sLISVS3ceO1REIBif3GN8w/l/RuH8Nq8Tdw6vCPJsW4+uGkIa7Ly+e7nPfx9xjqmLt7O1MVVW1QkeJ3kFpezaU8RM1dnM7R9EtFuB5ZlsTargJaJHuKiguOAtu4t4u8z1gFwXq+0wwpbIiIiDUV/pepYZWmstm6p0vLgrCW3UfVj8Dg8UAYl/iPrLmqTFB02I8owDLo1jyc1Lop/fLGOA/fUfPY3fbjq9R8AuOGtJTSPj+KJy3rx9qJMPluRhWEEt3w4qVkMl/av2o/r0xVZPDv7Z24adhJXDGp9RG0UERGpD+qWqmOVsSVQywrFZf5guImyOUPHPM7gasPFtcyuOhpNY9yM7hG+evPDF3TjtI7JtG7qDR3bmVfKb19dxGcrgmsKWRYUlQVYsT2P+6avCp139/sr2L6/hHunrUJERORYpMpNHavscDKtmt1SJRXhxl0t3HhdwdWGS2oZo3O0HhjTFX/A5OK+LRneJSW0ts07159MbnEZDpuNK177Hp/fBAsmnNmetPgo3l+yne9+3vMLVxcRETm2KNzUMTsGYNXeLVWxt5THXrWxp9cV3PW7OILhpllsFC9f2b/G8RYJHlokBBcP/PHeEUCwO6vSBb1bcMfU5XywdHuN10JwpWObzaDI56fMb9Ik2oVlWfz3+630aPnLs7xERETqgsJNHaus3NTWLVU5ribKXrV2sccdXJCvuJYByHWpeqiprn+bJgcNN3sKfXy1Noe/frYGgBm3nsqPW/Zz30erAdjy93PrprEiIiKHoDE3dcxBMDQEahkgXFpRzfHaq9ap8brjASixAod1/eLyYizL+uUTj1L/1k1CX//32kH8e3x/nPbgZ3r+mw3c99EqissCFJcFmL5sJ1+uzg6dn7EtF3/APKz3WbxlH/d8uIK84pohUERE5Ego3NQxW8Ut9tcSbkrM4KBhj8MTOuZxJwSf45dDwbKcZQybcioPz7s3Ai2t3UnJMfRsGU/bpGgGtG3C8C4p9GgRDGD/WbiVQLVpWM9+/TOzqq2hM/b5+fxz9s9h18vcW8yWPUWU+U1emLOBFdtzAbjkpYX874dtPD5zXdj5+aXlPDv7Z9Zl//JO5yIiIqBwU+ccFasP17a3VIkZrFJEOavCjdcTrJSUGGBaBw845WY5V824ihKzjPc3fRLJJoex2Qw+vGkIs28/Hbcj2MmWGF3VjTaobSJz7xqGy2ELCzqV/vX1BlZuz+OpWT9RUFrO2BfmM/ypufxxagb/+GJ9aDp6pYxtuaGvywMm5/9rHk/N+im0zo6IiMgv0ZibOmY3DLDArK1bqiLceBzRoWNeT2LV8/5SvE5vjdcBrNq+IOz73YW7SI5JiUSTa3DYwzOwv1qIeef6k7HbDF74bV/+NmMtUQ47g9ol8sb8LaFzxjw3D4AlW/eFdjivnHKeW1zOqGe+DZ1bvRfr/SXb2bI3uJjhnPW72VdUFhasREREaqNwU8fshh0s8Ptrq9wEBw1HVUz/BoiKaophWViGQbG/+KDhZvsB4Wbdtu9I7nJJBFt+cH8Y3oH12QXce26X0LTyEV1TGNE1GK4CpkXrRC9PzPyJQl/VwOj5G/bWer3qe10VlAYDnz9g8tLcjWHn9X1kFo9f0jNsUUEREZEDqVuqjtkruqX8gVrG3FQMGq6cIQVguGPwVAwQLik/+BYM23M3hX2/fseCg5wZeX1bNWHhPcM5r2ftu5XbbQZXD23Lbwe1qvX5s7umhHY8P9D2/SWMeGoun63MYuveYhK8Thy2qplcd72/AsuyWJq5n6/XVY3vyS8tZ+bqbPJLNSBZROREp3BTx6IqtlYoK68l3FAZbuKrDrpj8FR0+xSX7DvodXcW7gQg2gz246zfd+yNSRk3oPYKy3m9mjPhjPY8ckG3Wp/fkFPIrVMyABjdPZWTkmPCnv9+0z4uemEBv5+8mOnLdrAscz+nPvYNN7y1hL99tjain0FERI4/Cjd1zG0LhpuSQEnYccuyKK2o0HhcVZUbnNF4KwYSl5TuP+h1d/iCwWeoPzjId1vpsbeS8EnJMfSqWMjv2lPaAsGqTp+KY5cPbMUTl/Y65DXO7poa6qqqdOuUZaGvb3s3gwtfWEBeSfAcragsIiIac1PHomzBAbClB4y58QV8WBW9LZ6ohKonbDY8FU8csnLjLwYbDGzSiZlF69hhHtlGm/Xlzd8P5Jt1OZzXM43fDmrF/qIy0hOD44gcdhuX9GtJ8/goHvtiHX8a1Rm7zWD9rgIe+mQNCR4nQ9o3pX+bRD5evjN0zZyCg++7tSO3hDOfmMOr4/uHKj5ZeSW47DaaxgRXgi7y+flq7S5GdU8NzQATEZHGQ+GmjnkqVh8uPWDMTeW+UgBR1WZIAXgrxumUlObWek2/6SfbCAAGA9qcDavXkWtYFJUVEu2KqfU1DSXe42RsnxZAsJJDcs1zhrRP4qOJp4S+H9SuKae0T8LlsOF22Hn4gm4kxbhpmxwd2sTTMOA3A9L53w/balxv054i/vrpGoa2T2JDTiHTM3aQ6HXx9Z3DyC0u508frGDuT7u5a2QnJpzRvm4+uIiINBiFmzoWVbFvVOkBe0uVVkwNd5kWdnds2HNe7IBFsS+v1mvm7N9EwDBwWBZtOo8lfsXT5NntbN+9hk4tBkb+QzSAdtXG2SR4Xdw/piu7C3yhcNMuKZpJF/XEabfx5sKtAJzTI5XPVwZXSP5m/W6+Wb87dI2deaWMe3khy7dX3dOX527k3B5pZOWVYloWboeN/m3Cg6aIiBx/NOamjoXCzQEbYVZWbjyWCa7w6d6eynE6ZQXUZs/e9QAkmRa2mGRamMFurB05yyPX8GNQcmzVBqMpccEtKypnZA1u15Q/n9OFywfWPkMLCAs2APmlfsY8N4/LX/2eK15bxCUvLQytwxMwLVZuz8M0LXYX+JjyQyaz1+4Ke/3O3BLu+XAFW/YUReTziYhIZKhyU8eiKvaNqhFuyoN/EKMsCw7oSvLanEA5xWW1bzmwN28LAEkV23K2sHtZQyk79q2PYMuPTZcPbMX7S7bx53O6ANA5NY5v7hxGotdFvNfJpIt60LKJhzfmb+G53/Yhc28xOQWloQUB2zT10rd1Ez5cugOAgtLwDUonL9jCLWe2559f/cxz32ygWawbv2mFQs/MP55GyyYeNu8p4qGP1/DDln0s2LiXuXedAQQHis/bsAevy0G/avtyiYhI/VG4qWNRjspwEz7jp3ImlMe0wBUd9pzH5gKrmOKywlqvuacg+Ie5aUVwaulOhPKd7MjPjGjbj0UPX9CNP43qRIK3aqXitknh92/CGe1DY2lObtc0dCy/1E+s24HNFlw1+sNlO2pc/9nZP7Ngwx4Wbw3+fA4cvPzoZ2tZlrmf/GqhaOveYnYX+Hjg41WhbjGHzWDJfWcR73ECsGDDHt5YsIW/XdgjrAIlIiKRp3BTx6IqNsWsXI24UuVgYY9lgSMq7Dmv3Q3+gy/it7co2D2S5AhWfFrEpMH+newo2V3r+Y2J024LCzaHyzCMUNAAeOD8bozp1ZxuLeK4/s0l/JRdQKk/gGURCjYAafFRjOnVnJS4KB75dA1zf6r9Hj85c30o2EBwi4pJn6/l0xVZ/L/T2vHkrJ8AcDtsPPfbvmGvDZjBak/fVgl8sGQ7b36/lf9cMzA0q0xERI6Mwk0di3IE/0CVVqxGXKm0YrCwByM49acar8MDfij21x5u9lSsadPUHez2aJHQDvYvYXu5ds4+XPEeJ2d0bgbAhzcNAcBvmtwxdTmfVux79fZ1gxjaPgmAnPxS/vb5WgKmxakdkmga7WJ6RtX09Ck/1py1VXmsMthAcGPQnIJSmsVG4Q+YzN+4lye+XM/KHXlcPrBq9tcTM9fzz9/0qYNPLiLS+Cnc1LGoir2hfAeEmxJfMIh4jJrrrHgqqz21bLYJsK9iLE5TT/APb4umXWEz7LDKsCwL44CwJIdWuT+W3Wbnz+d0YW9hGRf2aREKNgDN4qL49/j+5Jf6Oa9HGuWmyYC2ifRvncjIaht//nZQK7qkxXH/R6uwam6Szvb9JQx8dDZp8VGUB0z2FFaNxao+rT07r5Qb3lyMacHLV/YLtfFwFJSWM2NlNmN6NcfjCv5+maaFYaDfDRE5ISjc1LEoZ3A8SJEV4Jq3huCy2fnXJTMo9QVnQkXVEm68Fa8prmU/KoA9/uBg5KSYNACap/YGoMSA/SV7SPTWspiMHJbmCR7+d8PJtT43rFOz0Ndum50rBrUGYFz/dN5dvI1rT2nLX87tgmEYnJQUzU1vLyXO42DbvpIa18rKC/5sY90OEmNcbN0bXqVbtLlqAcdBf/uKCWe055qhbdmRW0JaXBRfrs5m4aa9/N/oznhd4f8ZP/DRaj5ctoO7P1hB+2YxvHxlP27+71JK/QFaJXrZtLuI35/SNrRqtIhIY6NwU8eiKgYLb7AFyDULwITnp/+GxJTgtgMeo+aPwFMRbkoOWBun0l6zDGyQFNsSAHeTtjTzB8hx2NmZs4LENsMP3qCyYsjbBsm1b1wpR+7RC7tz21kdSIv3hI4NaZ/EsvvOwmYzeHHORp7+6ifK/MFtNe44qyPJsW5sNoMxPYPVlevfXMysNbtqvf6ewjIe+mQNq3fm8/6S7cRGOUKzvGLcDq4/tR1XvLYI07KI8zj5oVow2pBTyOWvfB8aGF0Zop6cuZ5L+rYk3ls1DskfMLEZRnDAtYjIcUzhpo5FOYML9OXaqyo0HxZt5rKy4L+ao201B8d6K6aGF5u1h5s9mIBB0ybtggdsdlpgJwfYnrOK7gcJN+s3zOCvc+5kp2HybLf/R7eTbzu6DyVhHHZbWLCpVBkSbhp2Etef2pZ9RWX8tKuQoe2b1ugeunpIm4OGm0rvL9kOhE9ff2HORl6Ys/GQr6ttu4risgCj/vktj1zQnfbNYpi3YQ//nreZMr9Jz5bx9GmVwA2nnQTA8m25/OmDFewp9PHejUNomxRNdl4pHpc9bJC2iMixQuGmjnlq2Q4h125je1FwMGrldO7w1wQ30iy2/DWeKyrZR3HFH83kph1Dx1s4YlhGITtyNxy0La8veowMpw2w8Z81/+UfCjf1xmG30SwuimZxNX/eAEPbJzHlhpP5KGMnA9o0YePuQiac0Z5Pl2dhsxk8OXN9qCvrD8M70DUtjte+2xQ2s6tSiwQPp3ZI4qddBSzNzK3x/JUnt+at77eSlVfKdW8urvH8jtwSZqzKxm9abMgpDK0JBDB5/mYuG5DOxS8uoGUTL1/ceip2m8HCjXt5c+FWbhp2Umiz1EMpD5iUB8xQl1qhz4/XaVfVSEQiQuGmjrldsbUeX1MU/Fd4U0fN6b5xUcFZUHm1hJud2RkAxAdMvLEtQsdbRDWF0kJ2FGyv9f1MM8D3ZXug4o/HN0YJRTuXEd1cM3KOFSe3axpal6fSZQPSAWieEMXEd5Yx4Yz2obEyZ3VNYeveIp6a9RNNvC7uPLsTsVGOsICwYnsuH2fspCxghrapuH9MV8YPac17i7fz6nebMGsZ+Azwjy9qLgr5n4Vb+U/FdTbkFNL+3hlhz3+5Jpvnf9uXzqmxJMe6cdptbNtXzN0frCDe42RtVj4pcVHs2F9CecBkyg2D2bK3iNvezWBkt1T+dbl+H0Xk11O4qWNR7trDzZZAcOxDoiO6xnNJMakA7MXEtExsRtUuGTv3BPdWao4jbAp5i5iWULqVHSV7an2/n7Z8zT6bgcc0SbS52GHz823Ga4xu/vwh21+Ql8mrc/4P0+bk1nNexWk/8jVm5NcbclISS+87K+yY3WbQLjmmxro51fVsmUDPlgkAnN01lSbRTpx2G+2bxXLPOV04o3MzFmzYw9VD27JmZz6/+/ciALqmxbEmq2ppgfN7NWfJ1v3syK05OLo6y4Kb314a+j7e48TrsoeqTgC78qu6yc559rvQ15+u2MmfRnWiabSbeRv2sHlPIQs27iU7r5TTOyZzSockTu2QzMbdhbw8dyNZeaVkbMvlf9efTPcW8TXaUlIWCM0WE5ETi8JNHfNEJRzy+dpmNjVNOAnDsvAbBvtL99PUU/Wv+Z37guMr0g6o+LRochLsmc8Of+37US36+SMABhhe2jbtxn/2LmHBrh8ZfYi2WQE/N30whuX24EDY/Z/8jkfHTj3k55Fj1ykdkmocq14tGtq+KXeN7ESC18lvBrRiydb9eJx23luyjQlntKekLMBPuwooLgsQ43Ywe10OLZt46NY8joWb9nJRn5b8fvKPYQEor6ScvJLw1blP7ZDEmJ7NeXHuRjZX7Mvldtjw+U1OeeybWtu+LruAl7/dxEV9W/DlqmyKyqqWVjjvX/MY1z+d8oDJ5r1FXNovHZfDxp3vLadvqwRS46MYN6AVp3es+m9tb6GP/yzYQq/0BHbl+7igd3Oi3TX/77A8YPLjln30bdWEKKeCksjxQuGmjkUd0C3VImCxw15VcUmMq7nRo7NJaxIDJnsddnbnZ4aFm6zCYLdTc3f47tUtknvAz7ATf41qD8DyvasB6Bffgc4dL+Q/C5ewwCzAKtqLER3eFVJpRcbroWAD8HHeWsZlfkvPVqcdzkeX44xhGKFtKwAGtg3+jvVoWVUVaVNtq4sRXVNCX1dOk/9o4lB+3LyPuz9YgWXBrcM78MmKnQxtn4RpWvzu5NahlZfP6prCY1+sI97rpH/rRK6vZfwPQFyUg86pcfywZV/Y+J/q3l1ctUbQsmrjjCrHHH2+Mpv0RA9d0+JwO+zM27AntF8YwOy1u/jLeV1JjYviTx+sYGduCbsLfaHZZad2SKJTSizfrM/h2cv70Ckllj2FZfx52kp6tUzg5jNOwmnXPsQixwqFmzoW5QyfRdPH1ZQdgaqpuk0T2tXyoniSLYu9wO496+mcUjUOYWdFt1PzmOZhL0lJ6Y3dsig3DHIKtpN6QGha7tsLNujZYjDd243EteAv5DgcbF49lXYDb6q17R+ufguA86NaYhTm8JGjjFe+n8RzCjdyEEkxbkb3SKNXegIWwcHN159Wy+840CTaxd8v7hn6fs6dw/D5TVLjoojzOJi9Nod12fncePpJOOw2lmbu54VvNrBiex43nn4SnVJjWbMzn9fmbWJXvg+vy05qXBSbDrJL+7Z9JbWuOQQwe10Os9flHPRzfffzHr77Ofjf3rnPzsNuMzAtC8uCr9fl8PRXP3FGp2QuH9iK0zslYzcM3luynQ+WbMe0LFo3jSa3uIz9xeWUlgdo4nXhsBv8tKuAAW0S6Z2ewLWntKUsYOKy2yguC/DkzJ9Ymrmfp8f1pm1SNOUBE4fNoCxg8v6S7XicdtbvKuCaIW1JjQ8OVLcsiyk/biM1LoozOjfDsixyCnzMXJ3N2D4tiI3S7DY5MSjc1DG3PXyTxH7Jvfg0O1h6d1oWMU1qX0gt2XCzjgC7c8On+WaVF4ANmh8QihyxKaQGTHY47OzIzggLN9n7NpJjs7BbFt3an0eUI4o+7mQWle1m4aYZtYabsoJsZgb2gc3G2F43kJyfzSdrnmduyXbW5iynS7NeR3U/5MTQPKHm1Phf0uaADVBHdE0Jqw71bdWE18YPCDtnaPskrj+tHbnFZQRMi3iPkyk/buPnXQVc2j8dj8tOyyYeLntpIcu359G+WQyD2iZyWsdk+rVuwsKNe/lidTafVWy5caCrh7QhO6+UL1Znhx0P1DIK+5v1u/lmfXDvscputkq1zVqr9OmKLD5dkcVfP1sLgNdlp7hat9uV/15ESlwUS7bup2UTD22aRjNvQ9XYuiVb9vP3i3syZ30Oa7LyQ9WtUzsksXTr/lAX3hers3nhin5kbMvFZbfRs2U8L8/dyCkdkkNVul+yr6iMBRv3MLJbqipVckxTuKlj1buHWtm99GgxBKqFGyO+Ra2va+aMASuP3dVmP1mWxXbKAIO0xAMW4TMMWuJkByaZu1fSr+P5oaeWbfgEgI4B8CQGw9SQFqewaPM0Fub/zBWmCbbw/6NauPQlCm02mpkG/TpdgC3gZ+Sy55gRZfDqgr/y1Nj3jvqeiERa9c1Uf3dy6xrPv3/TEHx+k5gDxtWM6dWcc3qkcc/oziTFuPl5VyEJXifFZQESvE5S4qKwrOCU+PRELxt3F7I0M5f+rZtQHjBp3TSayfO3sDYrn6/W7sJfEXp8fpN4j5PhnZsxb8MeSsoCxHmcjO6eSrcWcfzx3eWhNgxu15SFm/aGvq8ebCC4Zcf2/SU1vq60eOt+Rjw1t8Znrqw0VZq/YS+9HppZ47znvtnA1UPa8t7ibfgCJs3jo2gWG8XZ3VKIctpZuT2PPYU+Nu8tYtPuYFXskn4tefySnvx73ubQGKtTOyQxsG1TnHaDbftKaN3Ui9NuI7e4DJvNIK6WqtHuAh+bdhcyoE0iNpuBaVqUBcxQOPxmXQ4dUmJp3yx8SY1Cn59ol/2g24kETAvbEWw3srvAR9No11EtRaAtb45NCjf1qG+bEXTscB4seRSAYpsNYlJqPTfJ3QRK89hdVPUvxl27lrPPZmC3LNq2HlbjNZ1dTVhk7iUjJ4MLqx3/ZutXAJwcVfVeg7tcytObp/GD00b59h9xthoUdq2ZW2cBMCK+YzCgOVxc3/4iZmyfzle569i4fwMnNWkf9hrTMlmyawmmZdK3WV+cdpXA5djgtNsOWmmw2wxaNgmOA6o+vqiSYRh0SAmOnevWPJ5uzcPPuXVEh9DXa7Py+WJVNmd1TaFjSiwuh63WP36frcjmq7W7+M/vB3J6x2SWZe7H5zfplBLL1n3FLNq0l/N7N+e17zbz3uJt9G3dhDvP7sTSzP1MXbyNUd1SuWxAOvM37OHeaasoLguQGO0KjSO6qE8LdhcGZ6XZDCNYpfl2E2V+k6QYN4W+ckrLg5Ul04LX528OtW3L3mK27C3mhy37OJj3l2xnzvqcsL3R3pi/Jeyc5Fg3JyVH88PmfdhtBh1TYsncV0zv9AS6No9jfXYB32/aS2m5SbukaLqkxfH9pr3sLSojPdET1oXYxOvkjE7NsIAfNu9jR24J7ZKiOa1jMmt25pOe6CU90UPn1DhenLuR5dtySU/00LFZLLsLffRt1YRBbRNZl13AT7sKKCoLkOh1kpbgwbLgpbkbGXJSU16/egArd+Qxd/1uUuOjyNxXTM+W8fRskUCrpl5M02JNVj5b9hbhcdoZ1K4pV7/+A9n5pfxxREcGtk2kZRNP6Of93c+7+XpdDn84swNNol1YFRvOHU0YUog6MoZl1ba9X+OVn59PfHw8eXl5xMXF1ct7njH1DPaU7OHtc96mZ3JP7n+uLdNiY2hfVsa062uuJQIw9dPreGTvIoY5EvnX+VMhphmzF/yd2za8QyfTxvvXLK/xmm+/vJ0J2bNoiYsZ45cAUB4o57S3+lJowFvtr6T30LuBYBA5881+7MXP88mnc9o5z4WuU1a4i2HvnUmBzcbkkx+hX6exwSeK93Hbmycz2+Pm3GYD+Pvo10Ov2V+6n4mfXsGKouDAzpb2aO475VGGHGorCJETVElZgJ15JZyUXHORzyNV6PNT5POTEhfFRxk7iHLaGdkttcZ5a3bms2pnHhf0bs7O3FL+9P4KfAGTtVn5NI12cfOwkzi1QzLb9hcze20OG3cXYlmQGO0iymnjxy37KSj10zElhgUbqypNSTFu9hTWXAX7eOR12fEHgtWjA7kdNiwIbaNyMD1bxjOqeyovfLORQl/VWmWJ0S5KywPERjnonZ5Aq0Qv6Yle5q7fzaqdebRpGo3XZafQ58flsHFK+2RaN/WyckceyzL3s3pHPqO6pxLncbJyRx7RLjvXnxocnrB8ex5Ltu6nRUIU7ZvF0DzBQ5ukaGLcDpZl5mIzoFuLePYU+OiUGkuU045lWfhNC6c9GMCz80uZu343H2Xs5OxuKZzaIYnYKCc7c0tw2m289t0m0hO9/HFER3x+kyinjfkb9jJ73S627i2msNTPw2O70TYpGrejbmYWHsnfb4WberCzcCc5xTn0btYbgPJnevC2uZ/TSkpod+/eWl+zbMGTXPXzZACaBAKMMb2Uu2P4n7mXi93NefA3X9Z4TeGWeZwy50YChsGXF35O87h0vlj1Fnct+QdJ/gCzx83BFlO1+eNjn13Nf/csYWTAxRO/XxI6/u23DzNh83skmwZfXZ0R1rW2Zvp1jMtbhA34ZOyntIpvTVZhFjd/9ls2lO7BYVlEWRaFFd1cvaJS6JPUg0v63ULrinFClmWxfc9qvl32Gh/tmMteyvEDw6LSuLTXDXTvemnY58or2sPXGa+AYaN/l0tIP6BiVGlPyR5Wb/mGNVtmkV+yjzO7XE7/zhcd9F87X8z7K19v/YpkTzIXDLqTji0G1XpepXKznO93fs/6/evxODz0T+lPpwO7B0WOM6ZpHXZ3TGX1YObqbL5el0PfVk24tH9L9hWV8Y8v1tOtRRwpcVEMbJPID1v2sTO3hDM7N2N3gY+cAh+rd+bx6reb6Z2ewPm9m9MlLY72zWKYv2EPmfuKadPUS/82iXyxKpupi7fx/047iV35pXy+MotOqbHEeZyc3K4pHVNi+HDpDjbuLmRHRVddUZmfcr/J6B5pXHdqWzIyc4ODt6NdTF+2g8Vb9zPkpKakxEXx6YqsUJXL7bBxYZ8WfLM+J2wNpkpd0uJYW23Np1i3gw4pMazNKqCkPNiFeHK7RDbkFB0XIS/G7aBVopdd+aXsLSrD5bBhQNgYsUOJi3KQX+oPqxRWZzPA7bDTp1UC71xf+ybER0vh5hAaItzUsO1HeGMUDL0Vht9f6ylWSS5Xv30qS2vp2bm/xdlcOuLJmk8E/Fz17x4sczvoG3cSwztexL+X/JN9Vhk3W/HcdPW8sNPXbpvHZV/fhNOymDb0CVp3GIXlL+fG/wxggSPA5bGd+PNF74e/x/4t3PzuWXzniaKtuynnd/sdby9/lT2BYpr5/bza5GRSWp/Oc4uf5B23hVktWLS0eWnvTmRDcTbbjZqrL1caZHg5q+UwhvW/hU8WTOL1rG8pqNajMNTbkqsH38ugFkPxm36mrX2bT1a/RUZpzdkubXBycauzOX/QHaE1hfJK9vGPT37HxyXbws7t40rkop7X0735ycS4Yoh1xeJ1eAlYAVbsXsFf5tzJttLdYa8Z2qwvv+89gX4p/bDbwv+1sn7PWp787h6W5m8m3ubklKY9ubTfrXRPObLB2H7TT6m/lGhn9CHL0nm+PDJyMrCw6Na0G8mNcHd4y7LYnL+Z7MJsejXrRbSz5iKY1c8NWAEcNvW+H0tKywMNvmZQ5fYfm3YXEe9xkp4Y7HJav6uArXuLKAtYLN+Wy51nd8LjsvPTrgLKK8YCtUqMxuWwsbfQx5Kt++mYEkubpOjg7+aeIu56fwVLtu6nU0osY/u0oE+rBDbtLqJZrJuS8gBfrs4mzuPEHzDJ2JbLkJOSOK1jEgWl/oqKiJ0d+0uYvGAz0S4H3VvEk1dSTseUGMoDFm6njabRLjbmFDF1yTbiopwMaptIr/QEcovL2LK3mDU788kpKKU8YOFx2mkW52br3mIMI7jQZm3sNoP2yTE47AZ5JeXsLvDh85t4nHYCZu3VrEPp2yqBD28eGoGfVpXjLtw8//zzPP7442RnZ9OrVy/+9a9/MXDgwIOe/95773HfffexZcsWOnTowGOPPcY555xzWO91TIQbAF8BOKNrDOStbt2GGTy44AFiPE1ZWbSdYgNiTYsPz3uP1OQutb5mzQdXMT5/CaXVrtvUH+Cz054husPZYedalsUNb5/C94F8mpkwJLE72Xlb+N4qxGVZfDD6bdrU8od404w7uH7n5+Q4qv5odCgr44Vmw0kd81zwM5WXkPPDS3y38TO+KtnOvAMGEzosi+6mnbOb9afvSedQWLKH6WunMKN8N4Fa/oC39gdIsgyWOYxQYOroSSWvvIBd/uAgR8OyaFvup6sjDrvdxczAfkoq7oPDgoHe5mBzsLQwk1IDbJbFhY4k8ssK+Nrmq/V9D9QkEGBoSSn5NhsLPFH4K17TxOGlY1xb2iV2JMaTxPbcjXy17RvKqfmfV1d3UwamDiIpLp3EuFbERyXgcXgoKCtgX8le9uZvIyt3Extzf2ZjSQ4FFdtwxBoOOke3pEtKXzqn9Sc1OpXM/ExW71rCupzlrC7MpPr//XT0NmdI6+F0SepOib+EwvJCCsoKKCrLp7BkP2XlhZSXl1DuL6XEX4zD5iA9oT2tk7vTKr4Nsa5Y7IYdu81OQVkByzLnkp27hWh3PC2adqB7an86J3YOzQjML8tn1e6VbNi1jKKSfZSUFbC7YAd7S/eSFp1Gj9Zn0jWtP+0T2uOwOdiSt4XP17zNZ5s+o8zy0yW2NSe3G03/lqfQMqZlWJjL8+WxcMcC3sp4kRUFwfEhMYaTq7qN54JOl4aWRgiYARZlLWLa6v8wJ3sRZVaAnjGtOf2kczm11Zl0bNIxdE3Lsijxl5BTnENmQSa+8mLsNhepMakkeZJCwaksUEZZoAzTMvE6vUQ7ow8ZmMoCZZQGSvHYPYccdxYwA5QGSglYAYrKithbupd9pfswLZMkTxItYlqQ4E4IC7R7S/ayeNdi8kpzSYlOpX2T9jSPbl5r6LUsi8yCTJZsn8ee/G2kNDmJvmkn0zK2ZY3zywJlZBVlYcOGw+bA4/AQ546rsV7WrxHsBvHjsDkOGtLLzXJ8fh++gA+n3YnH4cFpa/ixe5W/K4XlhXgd3l/8h0aRz1/ropBHoyxQRn5ZPiXlJdhsNqId0cS74zEMg+y8UuI9zrCVuEv8JZQFyvA6vBSXgcdpx+WwUVoewGW3sS67gF0FpcRFOWibFENRRddZcqw7LHSWlgco9PlJinGHKnY7cktYsnU/JyVHk1dcTtMYN+2So8krKSfeYyOnaD9+vwMbUbgdtoPupXe0jqtw8+6773LVVVfx0ksvMWjQIJ555hnee+891q9fT7NmzWqcv2DBAk477TQmTZrEeeedxzvvvMNjjz3G0qVL6d69+y++3zETbo7Qmsx5zF33Lhf2v43UxJMOfmJpPqsnj+Szsp3scDhICgQYn3YqrS55q9bTd+5czOVfjGffAYMt72o+nKvOeqb29wiUs3fGHby9cTprXS46lpVxfY/riTnjL2FbQoSU7Cd/zXRW71zIhsIdxHuTGTH0z3iTOtY4NXPzN8zMeIV39q9gt93GSX6T37c4k3OH/Q27K5rtPzzPm0uf432vk/KK90oMBPh9wMvoXtfSrOcVEBX8uRbtXsvn8//GB7sXs9oV/n80HcsD3NP1WvoPuQMsi5xVU5m+6ElmmnnsctgptNlCwQXAbZqcVVzC/6WNIL7HZVCay9Ylr/JG4U/M8nrIt9f+L9FhxaVMbDGC/VYZH2fNZ0aUI+y6kdamrBwnFhucTqx6GHzowMBbsbN9vnn4JXkbBmYtwS/82lW/k/5qsc1pWcSaJvuq3fM0dyJeh4e9pfvIDRx8iwiXYcdp2LBho8QsD7vukfAYdqJtLmIcHqIdXnwBH/n+YvIDpZRaVbOdHBh4DAduuwuHYcdu2Ck1fRQFfGHnHYzX5qK5J4lou4d9vv1s89Uc5BtjOGjrSSE+qglup5cAFj5fAT8VbGVvLfci3uYm2Z2A2xFFwAywz5fLHn9hjTvhwKCJw0OiMw6bYVAa8LG/vIh804dF8GfoMmw4DTsuw47L5sBpOAhgUm4GKLcC+K0A5ZZJuWWG7rUNg2jDgcfmIGBZ+Ak+77MCBGr5nXBgw2Nz4LY5MAh2oVhYWJX/a1HxVdVxKv4Y2zAwAAOj4rcp+GqfFaDMCuCzAphY1c4xwAi2Mfja4Ot9lj+sbS5sJDi8xFWEHIOKkogVoNhfQl6glGLLT4zhpInDQ7wzlrioBJx2N2V+H+VmGT5/KfnlheT6iykx/bhtDjw2Fx6Hm4BlUhgopTDgw1fL74nXcNDUGUuUI4oom4uSgI+C8iLyAsVhv1dew0GsPYpYZzTRDi9lAR/55UXs8xdSagWIs7lIcHiJdsbgdkThMhwELBO/WUYgUI7fLKfcLMdv+vFbJgHAabPjtblw2134gZJAGfvLC8it+L0ASLZ76ZvYhSfOmVyj7b/GcRVuBg0axIABA3juueCAVtM0SU9P55ZbbuH//u//apw/btw4ioqK+PTTT0PHTj75ZHr37s1LL730i+93vIabIxIoh50ZULAT4ltCi36HPD1v10pmf/dX9hVngzuBk3v8rsa4l1rt2ww7l0FyZ0jpGpm2VzBLcvHlZeJp2hGcB6T/4n1kf3U/GTvmEe3w0K/77/AOuhFsByl1lxXx0w/Ps+TnT3DY7PRMP42Og26tuTKzZcGOJZCzBmv/VkryMikpK8AR8OONScXZcxy0PbXG+eWrPmBt5rdsKt3NJstHic0gMRBgQFQa/c95FlpV9DuXl7Bn6WTmrnuXDcW72Gf62Gu3k2+zUWIYxJomTQMBEk2TZFsU7aKbc1LTLqQkdsDlimFb1lLW7lrC2pJs1rqc7LbbaeEP0M1XRhdXAr2a9SWt47lgd7Lv5y9YlDmH+UYpOxwOYkyTaMsixjQrHhYuhxunw4vLEYXH4aE0UMrWkj1k2mGbw0GJzSCAQcAIVtp6+MpoZ4+mOFDGJluAlW5XWMAAaFleTpcyPwlG8I9RsiuBJlFN2FqwnVVmIWtdzlAQdJsm/Ut9nB/dluZxrViWvZhFVhEr3G4KapnZ1Kq8nFHFPi5vex6JSV35YukLvOsoJcPtDuv+jAsEOLeohPMTexLvbcbCrIV8a5TyfZQbXy2V0ijTpE25H69lUmYYZNkd7Lfbwq7psCxsFpTV0a7lDssK/uwDJnYsdtnt7HbU/i//Tr4y0vx+djgdbHY6DxmWHZZF71IfLUzYZocVbvdBz/eYJgZQbhihfzhIOMOy6uUfDbW9r8eyMCGsKn+sqX5/BgXsvPb7jIhe/7gJN2VlZXi9Xt5//33Gjh0bOj5+/Hhyc3P56KOParymVatW3H777dx2222hYw888ADTp09n+fKaM4h8Ph8+X9W/KPPz80lPT2/c4UYaTnkJ5O8EhxviWtReyapkBqB4LxTugpL94I4LLg0QnQSHmkbvK4Dti4Pvk9AK0nqFqlXh1zeDYW3fJvAkgCcRPE0qHgm1h0HThLxM2P0TlBeDFQiGOIcbWg2BykCYm4m1cQ67ts6lpLwIy7CRlNiBuHZnQvqgmoEUIG8H1qY55G5fhN9fTELTzji7joWkigHilgU5a2HLdxTv/Yn8gizAxDBNYt0JeJv3hW4XQmzFkgblpbDuU/avfJet+37CZ5YT44qnQ7vhuAbeELw3ldfdtYrStZ+wd+96zPJi/DYHHncs8QltiWraESOpPcS1hLJC2LcJq2gPpaX7MWx2nM4Y7C4vGHbKi3dTVJBFYdEuior3UFCylyJfHm57FHGeROK8ycR5k4iyR1GCSUlZISVFuygr3oPfX4rfMolyxRLtSSQ6qglRNgcObDhcMRixqRDTDAwb7N+Cb/dadu5Zx86S3ZQYkOiMpVVqH5K6XgTNukDRHsp3LmHz1u/Ytv8n8n25lJWX4DADOFwxpMe3pVu7kbi7XQixqbB3IyVrP2LbjkXszc+kPODDhkETT1NSEtrRNLUvhsMJZoDy0v3sy9vOvqKd7CvejYUNl9NDk5gUEmJaYBg2TLOcsvKSUPdmmT/YxWk3HDgcLpw2N06HC6c9CqfNgYNgNajMClBolVNi+rEDTgycGLjtLtyuGKLc8bgcXsoDPkp8uZSU5lNcVkBZeREEyrAqKiWGYYPK6ophhLqJDMMGhoGFgWWAWVGzsYxgl7aBgduw4zJsuAxbsFpjmphmOZZZjmX6sQLlmIFyLJsdMyoed3QysfGt8LjjKSnIYn/eFnILdlBQmhusVhg2LANwxeCNTiY+Og2vpwmFRbvZX5hFbvEu8kv24jf9uGxOXHYXLrubOE8S8TFpeB1ufKV5FZ83DzsQ44wmxpNEbGwaMTEtsLmjwbDjy9/Ozt2rySvKoqQ0n1LDIspwEOtJJCE6lYS4dNyuGAqLdlNQvJuCkn0U+PZTVFaA2+EhJiqBpjFpREU1Ia9kH7nFOZQUZlMW8OGrqFo57G4cTi8Opxe7MxqHy4vT5sDuLwv+XPwllAZ8OALlRGHQJL4VTRM7kRDXkqL9W8nctRQrLo0e51bNwo2E4ybc7Ny5kxYtWrBgwQIGDx4cOn733Xczd+5cFi1aVOM1LpeL//znP1x++eWhYy+88AIPPfQQu3btqnH+gw8+yEMPPVTjuMKNiIjI8eNIws2xW9+KkHvuuYe8vLzQY9u2bb/8IhERETluNegcyaSkJOx2e42Ky65du0hNrbkIFUBqauoRne92u3G73bU+JyIiIo1Pg1ZuXC4X/fr1Y/bs2aFjpmkye/bssG6q6gYPHhx2PsCsWbMOer6IiIicWBp8davbb7+d8ePH079/fwYOHMgzzzxDUVER11xzDQBXXXUVLVq0YNKkSQDceuutnH766Tz55JOce+65TJkyhcWLF/PKK6805McQERGRY0SDh5tx48axe/du7r//frKzs+nduzdffPEFKSnBGRGZmZnYqk19GzJkCO+88w5/+ctf+POf/0yHDh2YPn36Ya1xIyIiIo1fg69zU99OiHVuREREGhnNlhIREZETlsKNiIiINCoKNyIiItKoKNyIiIhIo6JwIyIiIo2Kwo2IiIg0Kgo3IiIi0qgo3IiIiEij0uArFNe3yjUL8/PzG7glIiIicrgq/24fztrDJ1y4KSgoACA9Pb2BWyIiIiJHqqCggPj4+EOec8Jtv2CaJjt37iQ2NhbDMCJ23fz8fNLT09m2bZu2dahDus/1R/e6fug+1w/d5/pTV/fasiwKCgpo3rx52J6TtTnhKjc2m42WLVvW2fXj4uL0H0490H2uP7rX9UP3uX7oPtefurjXv1SxqaQBxSIiItKoKNyIiIhIo6JwEyFut5sHHngAt9vd0E1p1HSf64/udf3Qfa4fus/151i41yfcgGIRERFp3FS5ERERkUZF4UZEREQaFYUbERERaVQUbkRERKRRUbiJgOeff542bdoQFRXFoEGD+OGHHxq6Scedb7/9ljFjxtC8eXMMw2D69Olhz1uWxf33309aWhoej4cRI0bw888/h52zb98+rrjiCuLi4khISODaa6+lsLCwHj/FsW/SpEkMGDCA2NhYmjVrxtixY1m/fn3YOaWlpUyYMIGmTZsSExPDxRdfzK5du8LOyczM5Nxzz8Xr9dKsWTPuuusu/H5/fX6UY9qLL75Iz549Q4uYDR48mBkzZoSe1z2uG3//+98xDIPbbrstdEz3OjIefPBBDMMIe3Tu3Dn0/DF3ny35VaZMmWK5XC7r9ddft1avXm1df/31VkJCgrVr166Gbtpx5fPPP7fuvfde68MPP7QAa9q0aWHP//3vf7fi4+Ot6dOnW8uXL7fOP/98q23btlZJSUnonFGjRlm9evWyvv/+e+u7776z2rdvb11++eX1/EmObSNHjrTeeOMNa9WqVVZGRoZ1zjnnWK1atbIKCwtD59x4441Wenq6NXv2bGvx4sXWySefbA0ZMiT0vN/vt7p3726NGDHCWrZsmfX5559bSUlJ1j333NMQH+mY9PHHH1ufffaZ9dNPP1nr16+3/vznP1tOp9NatWqVZVm6x3Xhhx9+sNq0aWP17NnTuvXWW0PHda8j44EHHrC6detmZWVlhR67d+8OPX+s3WeFm19p4MCB1oQJE0LfBwIBq3nz5takSZMasFXHtwPDjWmaVmpqqvX444+HjuXm5lput9v63//+Z1mWZa1Zs8YCrB9//DF0zowZMyzDMKwdO3bUW9uPNzk5ORZgzZ0717Ks4H11Op3We++9Fzpn7dq1FmAtXLjQsqxgELXZbFZ2dnbonBdffNGKi4uzfD5f/X6A40iTJk2s1157Tfe4DhQUFFgdOnSwZs2aZZ1++umhcKN7HTkPPPCA1atXr1qfOxbvs7qlfoWysjKWLFnCiBEjQsdsNhsjRoxg4cKFDdiyxmXz5s1kZ2eH3ef4+HgGDRoUus8LFy4kISGB/v37h84ZMWIENpuNRYsW1Xubjxd5eXkAJCYmArBkyRLKy8vD7nXnzp1p1apV2L3u0aMHKSkpoXNGjhxJfn4+q1evrsfWHx8CgQBTpkyhqKiIwYMH6x7XgQkTJnDuueeG3VPQ73Ok/fzzzzRv3px27dpxxRVXkJmZCRyb9/mE2zgzkvbs2UMgEAj7YQGkpKSwbt26BmpV45OdnQ1Q632ufC47O5tmzZqFPe9wOEhMTAydI+FM0+S2225j6NChdO/eHQjeR5fLRUJCQti5B97r2n4Wlc9J0MqVKxk8eDClpaXExMQwbdo0unbtSkZGhu5xBE2ZMoWlS5fy448/1nhOv8+RM2jQICZPnkynTp3IysrioYce4tRTT2XVqlXH5H1WuBE5QU2YMIFVq1Yxb968hm5Ko9SpUycyMjLIy8vj/fffZ/z48cydO7ehm9WobNu2jVtvvZVZs2YRFRXV0M1p1EaPHh36umfPngwaNIjWrVszdepUPB5PA7asduqW+hWSkpKw2+01RoTv2rWL1NTUBmpV41N5Lw91n1NTU8nJyQl73u/3s2/fPv0sajFx4kQ+/fRTvvnmG1q2bBk6npqaSllZGbm5uWHnH3iva/tZVD4nQS6Xi/bt29OvXz8mTZpEr169+Oc//6l7HEFLliwhJyeHvn374nA4cDgczJ07l2effRaHw0FKSorudR1JSEigY8eObNiw4Zj8nVa4+RVcLhf9+vVj9uzZoWOmaTJ79mwGDx7cgC1rXNq2bUtqamrYfc7Pz2fRokWh+zx48GByc3NZsmRJ6Jyvv/4a0zQZNGhQvbf5WGVZFhMnTmTatGl8/fXXtG3bNuz5fv364XQ6w+71+vXryczMDLvXK1euDAuTs2bNIi4ujq5du9bPBzkOmaaJz+fTPY6g4cOHs3LlSjIyMkKP/v37c8UVV4S+1r2uG4WFhWzcuJG0tLRj83c64kOUTzBTpkyx3G63NXnyZGvNmjXWDTfcYCUkJISNCJdfVlBQYC1btsxatmyZBVhPPfWUtWzZMmvr1q2WZQWngickJFgfffSRtWLFCuuCCy6odSp4nz59rEWLFlnz5s2zOnTooKngB7jpppus+Ph4a86cOWFTOouLi0Pn3HjjjVarVq2sr7/+2lq8eLE1ePBga/DgwaHnK6d0nn322VZGRob1xRdfWMnJyZo6W83//d//WXPnzrU2b95srVixwvq///s/yzAMa+bMmZZl6R7XpeqzpSxL9zpS7rjjDmvOnDnW5s2brfnz51sjRoywkpKSrJycHMuyjr37rHATAf/617+sVq1aWS6Xyxo4cKD1/fffN3STjjvffPONBdR4jB8/3rKs4HTw++67z0pJSbHcbrc1fPhwa/369WHX2Lt3r3X55ZdbMTExVlxcnHXNNddYBQUFDfBpjl213WPAeuONN0LnlJSUWDfffLPVpEkTy+v1WhdeeKGVlZUVdp0tW7ZYo0ePtjwej5WUlGTdcccdVnl5eT1/mmPX73//e6t169aWy+WykpOTreHDh4eCjWXpHtelA8ON7nVkjBs3zkpLS7NcLpfVokULa9y4cdaGDRtCzx9r99mwLMuKfD1IREREpGFozI2IiIg0Kgo3IiIi0qgo3IiIiEijonAjIiIijYrCjYiIiDQqCjciIiLSqCjciIiISKOicCMiJyTDMJg+fXpDN0NE6oDCjYjUu6uvvhrDMGo8Ro0a1dBNE5FGwNHQDRCRE9OoUaN44403wo653e4Gao2INCaq3IhIg3C73aSmpoY9mjRpAgS7jF588UVGjx6Nx+OhXbt2vP/++2GvX7lyJWeeeSYej4emTZtyww03UFhYGHbO66+/Trdu3XC73aSlpTFx4sSw5/fs2cOFF16I1+ulQ4cOfPzxx6Hn9u/fzxVXXEFycjIej4cOHTrUCGMicmxSuBGRY9J9993HxRdfzPLly7niiiv4zW9+w9q1awEoKipi5MiRNGnShB9//JH33nuPr776Kiy8vPjii0yYMIEbbriBlStX8vHHH9O+ffuw93jooYe47LLLWLFiBeeccw5XXHEF+/btC73/mjVrmDFjBmvXruXFF18kKSmp/m6AiBy9OtmOU0TkEMaPH2/Z7XYrOjo67PHoo49alhXcvfzGG28Me82gQYOsm266ybIsy3rllVesJk2aWIWFhaHnP/vsM8tms1nZ2dmWZVlW8+bNrXvvvfegbQCsv/zlL6HvCwsLLcCaMWOGZVmWNWbMGOuaa66JzAcWkXqlMTci0iDOOOMMXnzxxbBjiYmJoa8HDx4c9tzgwYPJyMgAYO3atfTq1Yvo6OjQ80OHDsU0TdavX49hGOzcuZPhw4cfsg09e/YMfR0dHU1cXBw5OTkA3HTTTVx88cUsXbqUs88+m7FjxzJkyJCj+qwiUr8UbkSkQURHR9foJooUj8dzWOc5nc6w7w3DwDRNAEaPHs3WrVv5/PPPmTVrFsOHD2fChAk88cQTEW+viESWxtyIyDHp+++/r/F9ly5dAOjSpQvLly+nqKgo9Pz8+fOx2Wx06tSJ2NhY2rRpw+zZs39VG5KTkxk/fjz//e9/eeaZZ3jllVd+1fVEpH6ociMiDcLn85GdnR12zOFwhAbtvvfee/Tv359TTjmFt99+mx9++IF///vfAFxxxRU88MADjB8/ngcffJDdu3dzyy23cOWVV5KSkgLAgw8+yI033kizZs0YPXo0BQUFzJ8/n1tuueWw2nf//ffTr18/unXrhs/n49NPPw2FKxE5tinciEiD+OKLL0hLSws71qlTJ9atWwcEZzJNmTKFm2++mbS0NP73v//RtWtXALxeL19++SW33norAwYMwOv1cvHFF/PUU0+FrjV+/HhKS0t5+umnufPOO0lKSuKSSy457Pa5XC7uuecetmzZgsfj4dRTT2XKlCkR+OQiUtcMy7Kshm6EiEh1hmEwbdo0xo4d29BNEZHjkMbciIiISKOicCMiIiKNisbciMgxR73lIvJrqHIjIiIijYrCjYiIiDQqCjciIiLSqCjciIiISKOicCMiIiKNisKNiIiINCoKNyIiItKoKNyIiIhIo6JwIyIiIo3K/wc3mWHeEGA2cwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss\n",
    "plt.plot(epochs_list, train_losses, label = \"Train Loss\")\n",
    "plt.plot(epochs_list, val_losses, label = \"Validation Loss\")\n",
    "plt.plot(epochs_list, test_losses, label = \"Test Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01868731 0.47328401990411806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        out, log_probs = model(batch.x.float(), batch.edge_index)\n",
    "        ypred_gnn = out\n",
    "        y_true = batch.y.view(-1, 1)\n",
    "        val_mse = mean_squared_error(y_true, ypred_gnn)\n",
    "        val_r2 = r2_score(y_true, ypred_gnn)\n",
    "print(val_mse, val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def pyg_to_networkx(graph_data):\n",
    "    \"\"\"Converts a torch_geometric.data.Data object to a networkx.Graph.\"\"\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes with features\n",
    "    for i, features in enumerate(graph_data.x.numpy()):\n",
    "        G.add_node(i, features=features)\n",
    "\n",
    "    # Add edges\n",
    "    edge_list = graph_data.edge_index.numpy().T\n",
    "    for u, v in edge_list:\n",
    "        if graph_data.edge_attr is not None:\n",
    "            edge_attr = graph_data.edge_attr[np.where((graph_data.edge_index[0] == u) & (graph_data.edge_index[1] == v))].numpy().flatten()\n",
    "            G.add_edge(u, v, edge_attr=edge_attr)\n",
    "        else:\n",
    "            G.add_edge(u, v)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pyg_to_networkx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.x.numpy().shape\n",
    "target = graph.y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1389, 43])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "# 1. Compute Adjacency Kernel\n",
    "K_adjacency = rbf_kernel(distance_matrix)\n",
    "\n",
    "# 2. Compute Feature Kernel\n",
    "K_features = rbf_kernel(gdf[features[10:]].to_numpy())\n",
    "\n",
    "# 3. Combine Kernels (Weighted Summation)\n",
    "alpha = 0.5  # Tune this parameter\n",
    "K = alpha * K_adjacency + (1 - alpha) * K_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge Regression MSE: 0.01630047759084859\t Kernel Ridge Regression r-squared: 0.41395627233916776\t\n",
      "Support Vector Regression MSE: 0.015622909583880703\t Support Vector Regression r-squared: 0.43831656965770227\t\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(K_features, target, test_size=0.2, random_state=91218)\n",
    "krr = KernelRidge(alpha=1.0)\n",
    "krr.fit(X_train, y_train)\n",
    "y_pred = krr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Kernel Ridge Regression MSE: {mse}\\t\",f\"Kernel Ridge Regression r-squared: {r2}\\t\")\n",
    "\n",
    "svr = SVR() \n",
    "svr.fit(X_train, y_train)\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred_svr)\n",
    "r2 = r2_score(y_test, y_pred_svr)\n",
    "print(f\"Support Vector Regression MSE: {mse}\\t\",f\"Support Vector Regression r-squared: {r2}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (1273378216.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[47], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "if task == \"reg\":\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psAwbtMpPgqP"
   },
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "h, _ = untrained(graph.x.float(), graph.edge_index)\n",
    "\n",
    "# Train TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "         init='pca').fit_transform(h.detach())\n",
    "\n",
    "unique_labels = np.unique(graph.y)\n",
    "labels = ['Moderate Poor', 'Non-vulnerable', 'Severe Poor', 'Vulnerable']\n",
    "\n",
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "# Scatter plot with different colors for each class\n",
    "for label in unique_labels:\n",
    "    indices = graph.y == label\n",
    "    plt.scatter(tsne[indices, 0], tsne[indices, 1], s=20, label=labels[label])\n",
    "    # Add legend\n",
    "plt.legend(title=\"Class Labels\", loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFcvr6KMPkNV"
   },
   "outputs": [],
   "source": [
    "h, _ = model(graph.x.float(), graph.edge_index)\n",
    "\n",
    "# Train TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "         init='pca').fit_transform(h.detach())\n",
    "\n",
    "unique_labels = np.unique(graph.y)\n",
    "labels = ['Moderate Poor', 'Non-vulnerable', 'Severe Poor', 'Vulnerable']\n",
    "\n",
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "# Scatter plot with different colors for each class\n",
    "for label in unique_labels:\n",
    "    indices = graph.y == label\n",
    "    plt.scatter(tsne[indices, 0], tsne[indices, 1], s=20, label=labels[label])\n",
    "# Add legend\n",
    "plt.legend(title=\"Class Labels\", loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(graph.x.float(), graph.edge_index)\n",
    "i, y_pred = output[1].max(1)\n",
    "y_true = graph.y\n",
    "cm = confusion_matrix(graph.y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(len(labels),len(labels)))\n",
    "cm_prop = cm.astype('float') / cm.sum(axis=1)\n",
    "sns.heatmap(cm_prop, annot = True, xticklabels=labels, yticklabels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(len(labels),len(labels)))\n",
    "sns.heatmap(cm.astype('int'), annot = True, xticklabels=labels, yticklabels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "source": [
    "class GCN(torch.nn.Module):\n",
    "  \"\"\"Graph Convolutional Network\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out):\n",
    "    super().__init__()\n",
    "    self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "    self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.01,\n",
    "                                      0)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.5)\n",
    "    h = self.gcn1(h, edge_index)\n",
    "    h = torch.relu(h)\n",
    "    h = F.dropout(h, p=0.5)\n",
    "    h = self.gcn2(h, edge_index)\n",
    "    return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "source": [
    "class GAT(torch.nn.Module):\n",
    "  \"\"\"Graph Attention Network\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
    "    super().__init__()\n",
    "    self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
    "    self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.005,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.6, training=self.training)\n",
    "    h = self.gat1(x, edge_index)\n",
    "    h = F.elu(h)\n",
    "    h = F.dropout(h, p=0.6, training=self.training)\n",
    "    h = self.gat2(h, edge_index)\n",
    "    return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "source": [
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def train(model, data):\n",
    "    \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = model.optimizer\n",
    "    epochs = 200\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        _, out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "        val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if(epoch % 10 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
    "                  f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                  f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    return model\n",
    "\n",
    "def test(model, data):\n",
    "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
    "    model.eval()\n",
    "    _, out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
