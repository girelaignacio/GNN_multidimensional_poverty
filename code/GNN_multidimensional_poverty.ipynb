{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igirela/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/igirela/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3QBFCJifrdZ0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igirela/anaconda3/lib/python3.9/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.data\n",
    "import torch_geometric.transforms as transforms\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read spatial data: Nigeria DHS 20-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uR4QbIm94HSw"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "df = gpd.read_file(\"../data/nga_dhs20-21.shp\")\n",
    "gdf = gpd.GeoDataFrame(df, crs=\"EPSG:4326\")\n",
    "#gdf = gdf.to_crs(\"EPSG:32617\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "BRVzB0Jp65lW",
    "outputId": "f473b51e-a908-4bed-ceb4-c146d6d85c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GeometryArray>\n",
       "[ <POINT (8.507 7.72)>, <POINT (8.552 7.718)>, <POINT (8.991 7.347)>,\n",
       "   <POINT (8.15 7.21)>, <POINT (8.408 6.881)>, <POINT (7.951 7.805)>,\n",
       " <POINT (7.838 7.595)>, <POINT (8.125 7.605)>, <POINT (8.503 7.689)>,\n",
       " <POINT (8.582 7.845)>,\n",
       " ...\n",
       "  <POINT (3.19 8.318)>, <POINT (4.022 7.953)>, <POINT (4.191 8.202)>,\n",
       " <POINT (4.431 7.977)>,  <POINT (4.104 7.85)>, <POINT (3.588 7.828)>,\n",
       "  <POINT (3.343 8.05)>, <POINT (3.018 7.948)>, <POINT (3.291 7.341)>,\n",
       " <POINT (3.948 7.786)>]\n",
       "Length: 1383, dtype: geometry"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.geometry.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTvhxUcW5qgp",
    "outputId": "990f876c-968f-4d49-9725-a3b13fd93b64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1687761/4188193525.py:1: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroids = np.array([(point.x, point.y) for point in df.geometry.centroid])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.506936, 7.720049],\n",
       "       [8.552142, 7.717922],\n",
       "       [8.991185, 7.346602],\n",
       "       ...,\n",
       "       [3.017661, 7.947632],\n",
       "       [3.291019, 7.341286],\n",
       "       [3.948039, 7.785664]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = np.array([(point.x, point.y) for point in df.geometry.centroid])\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build distance matrix\n",
    "\n",
    "We build a proximity matrix between the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "lx3-Bvbl5qsk",
    "outputId": "534c288e-adc0-4b3d-8eba-a18a3bba16e2"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "distance_matrix = cdist(np.unique(centroids, axis = 0), np.unique(centroids, axis = 0), 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Rs-v7sM5q5T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  7.90917123,  7.11335248, ..., 16.77679502,\n",
       "        17.73958348, 18.81761545],\n",
       "       [ 7.90917123,  0.        ,  0.8931784 , ..., 10.93767371,\n",
       "        11.43550126, 12.22038214],\n",
       "       [ 7.11335248,  0.8931784 ,  0.        , ..., 11.1203557 ,\n",
       "        11.72264204, 12.58043899],\n",
       "       ...,\n",
       "       [16.77679502, 10.93767371, 11.1203557 , ...,  0.        ,\n",
       "         1.47642768,  2.79842185],\n",
       "       [17.73958348, 11.43550126, 11.72264204, ...,  1.47642768,\n",
       "         0.        ,  1.33305874],\n",
       "       [18.81761545, 12.22038214, 12.58043899, ...,  2.79842185,\n",
       "         1.33305874,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.817615452436154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance = np.max(distance_matrix)\n",
    "max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_proximity_matrix = np.zeros_like(distance_matrix)\n",
    "for i in range(len(distance_matrix)):\n",
    "    for j in range(len(distance_matrix)):\n",
    "        proximity = (max_distance - distance_matrix[i, j]) / max_distance\n",
    "        proximity = max(0, proximity)\n",
    "        weighted_proximity_matrix[i, j] = proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(weighted_proximity_matrix.min(),weighted_proximity_matrix.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.995\n",
    "weighted_proximity_matrix[weighted_proximity_matrix < threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_proximity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transform data to tensor\n",
    "\n",
    "Create torch_geometric.data.Data object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform proximity matrix to tensor and create edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = torch.tensor(weighted_proximity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = adj_matrix.nonzero().t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 1380, 1381, 1382],\n",
       "        [   0,    1,    2,  ..., 1380, 1381, 1382]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get edge attributes (given by proximity of clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WIBVjlFAI4Vt"
   },
   "outputs": [],
   "source": [
    "edge_attr = []\n",
    "for i in range(edges.size(1)):\n",
    "    edge_attr.append([adj_matrix[edges[0][i], edges[1][0]]])\n",
    "\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dhsclst', 'd_cm', 'd_nutr', 'd_satt', 'd_educ', 'd_elct', 'd_wtr',\n",
       "       'd_sani', 'd_hsg', 'd_ckfl', 'd_asst', 'sexfeml', 'sexmale', 'agc70_4',\n",
       "       'a710_14', 'a715_17', 'a718_59', 'agc75_9', 'agc760_', 'arearrl',\n",
       "       'arearbn', 'reginAb', 'rgnAdmw', 'rgnAk_I', 'rgnAnmb', 'regnBch',\n",
       "       'rgnByls', 'reginBn', 'regnBrn', 'rgnCr_R', 'regnDlt', 'rgnEbny',\n",
       "       'reginEd', 'regnEkt', 'regnEng', 'regnFCT', 'regnGmb', 'reginIm',\n",
       "       'regnJgw', 'regnKdn', 'reginKn', 'rgnKtsn', 'regnKbb', 'reginKg',\n",
       "       'regnKwr', 'regnLgs', 'rgnNsrw', 'regnNgr', 'regnOgn', 'regnOnd',\n",
       "       'regnOsn', 'reginOy', 'regnPlt', 'rgnRvrs', 'regnSkt', 'regnTrb',\n",
       "       'reginYb', 'rgnZmfr', 'hdshpf_', 'hdshpm_', 'categry', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(gdf.columns[list(range(11, gdf.shape[1]-4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1687761/48258848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sexmale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'agc760_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arearrl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'reginAb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#,'hdshpm_']:#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0;31m#'d_cm', 'd_nutr', 'd_satt', 'd_educ']:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# Avoid multicollineality\n",
    "for i in ['sexmale','agc760_','arearrl','reginAb']:#,'hdshpm_']:#,\n",
    "         #'d_cm', 'd_nutr', 'd_satt', 'd_educ']:\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTOdbO8IQI4f"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(np.array(gdf[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.Categorical(gdf['categry'])\n",
    "numerical_categories = target.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tensor = torch.tensor(numerical_categories, dtype=torch.long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(numerical_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYrOagwsPxlj",
    "outputId": "703aa669-2e31-4795-c53f-fe6d45373a3c"
   },
   "outputs": [],
   "source": [
    "graph = torch_geometric.data.Data(x=x, edge_index=edges, edge_attr = edge_attr,y=target_tensor)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1BM5KgFQyxZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "\n",
    "# Get list of degrees for each node\n",
    "degrees = degree(graph.edge_index[0]).numpy()\n",
    "\n",
    "# Count the number of nodes for each degree\n",
    "numbers = Counter(degrees)\n",
    "\n",
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(18, 7))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "plt.bar(numbers.keys(),\n",
    "        numbers.values(),\n",
    "        color='#0A047A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of nodes\n",
    "num_nodes = graph.num_nodes\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sizes of the train, validation, and test sets\n",
    "train_size = int(0.8 * num_nodes)\n",
    "val_size = int(0.1 * num_nodes)\n",
    "test_size = num_nodes - train_size - val_size\n",
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random permutations of node indices\n",
    "perm = torch.randperm(num_nodes)\n",
    "\n",
    "# Create boolean masks\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[perm[:train_size]] = True\n",
    "val_mask[perm[train_size:train_size + val_size]] = True\n",
    "test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "# Add the masks to the graph object\n",
    "graph.train_mask = train_mask\n",
    "graph.val_mask = val_mask\n",
    "graph.test_mask = test_mask\n",
    "\n",
    "print(graph) #now the graph contains the masks."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #check if cuda is available\n",
    "graph = graph.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention network\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out, n_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads = n_heads)\n",
    "        self.norm1 = torch.nn.LayerNorm(dim_h * n_heads)\n",
    "        self.gat2 = GATv2Conv(dim_h*n_heads, dim_out, heads = 1)\n",
    "        self.linear = torch.nn.Linear(dim_out, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x1 = F.dropout(x, p = 0.5, training = self.training)\n",
    "        x = self.gat1(x1, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.leaky_relu(x, negative_slope=0.02)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return x, F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "source": [
    "class GAT(torch.nn.Module):\n",
    "  \"\"\"Graph Attention Network\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
    "    super().__init__()\n",
    "    self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
    "    self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.005,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.6, training=self.training)\n",
    "    h = self.gat1(x, edge_index)\n",
    "    h = F.elu(h)\n",
    "    h = F.dropout(h, p=0.6, training=self.training)\n",
    "    h = self.gat2(h, edge_index)\n",
    "    return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "source": [
    "class GCN(torch.nn.Module):\n",
    "  \"\"\"Graph Convolutional Network\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out):\n",
    "    super().__init__()\n",
    "    self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "    self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.01,\n",
    "                                      0)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.5)\n",
    "    h = self.gcn1(h, edge_index)\n",
    "    h = torch.relu(h)\n",
    "    h = F.dropout(h, p=0.5)\n",
    "    h = self.gcn2(h, edge_index)\n",
    "    return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = graph.x.size(1)  \n",
    "dim_h = 20 \n",
    "dim_out = len(graph.y.unique()) # Number of classes \n",
    "n_heads = 16  \n",
    "\n",
    "# Create an instance of your GAT model\n",
    "model = GAT(dim_in, dim_h, dim_out, n_heads)\n",
    "untrained = GAT(dim_in, dim_h, dim_out, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(),weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, graph, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out, log_probs = model(graph.x.float(), graph.edge_index)\n",
    "    loss = criterion(log_probs[graph.train_mask], graph.y[graph.train_mask]) #only compute the loss on the train nodes.\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, graph, criterion, mask): #mask parameter added.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out, log_probs = model(graph.x.float(), graph.edge_index)\n",
    "        loss = criterion(log_probs[mask], graph.y[mask]) #use the mask parameter.\n",
    "    return loss.item()\n",
    "\n",
    "# Training loop\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, graph, optimizer, criterion)\n",
    "    val_loss = test(model, graph, criterion, graph.val_mask) #pass the validation mask\n",
    "    test_loss = test(model, graph, criterion, graph.test_mask) #pass the test mask\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "vVmeKB1OuADf",
    "outputId": "3ba14774-a199-47c7-aa47-fc6b1c4a6685"
   },
   "source": [
    "%%time\n",
    "\n",
    "# Create GAT\n",
    "gat = GAT(dataset.num_features, 8, dataset.num_classes)\n",
    "print(gat)\n",
    "\n",
    "# Train\n",
    "train(gat, data)\n",
    "\n",
    "# Test\n",
    "acc = test(gat, data)\n",
    "print(f'GAT test accuracy: {acc*100:.2f}%n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "cWFE3gnUo7nA"
   },
   "source": [
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def train(model, data):\n",
    "    \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = model.optimizer\n",
    "    epochs = 200\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        _, out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "        val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if(epoch % 10 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
    "                  f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                  f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    return model\n",
    "\n",
    "def test(model, data):\n",
    "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
    "    model.eval()\n",
    "    _, out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psAwbtMpPgqP"
   },
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "h, _ = untrained(graph.x.float(), graph.edge_index)\n",
    "\n",
    "# Train TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "         init='pca').fit_transform(h.detach())\n",
    "\n",
    "unique_labels = np.unique(graph.y)\n",
    "labels = ['Moderate Poor', 'Non-vulnerable', 'Severe Poor', 'Vulnerable']\n",
    "\n",
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "# Scatter plot with different colors for each class\n",
    "for label in unique_labels:\n",
    "    indices = graph.y == label\n",
    "    plt.scatter(tsne[indices, 0], tsne[indices, 1], s=50, label=labels[label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFcvr6KMPkNV"
   },
   "outputs": [],
   "source": [
    "h, _ = model(graph.x.float(), graph.edge_index)\n",
    "\n",
    "# Train TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate='auto',\n",
    "         init='pca').fit_transform(h.detach())\n",
    "\n",
    "unique_labels = np.unique(graph.y)\n",
    "labels = ['Moderate Poor', 'Non-vulnerable', 'Severe Poor', 'Vulnerable']\n",
    "\n",
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "# Scatter plot with different colors for each class\n",
    "for label in unique_labels:\n",
    "    indices = graph.y == label\n",
    "    plt.scatter(tsne[indices, 0], tsne[indices, 1], s=50, label=labels[label])\n",
    "# Add legend\n",
    "plt.legend(title=\"Class Labels\", loc=\"upper right\")\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, _ = model(graph.x.float(), graph.edge_index)\n",
    "torch.isinf(h.detach()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
